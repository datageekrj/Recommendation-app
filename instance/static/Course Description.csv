id,description
1,"Algorithms of the Intelligent Web - Algorithms of the Intelligent Web teaches you how to create machine learning applications that crunch and wrangle data collected from users, web applications, and website logs. In this totally revised edition, you’ll look at intelligent algorithms that extract real value from data. Key machine learning concepts are explained with code examples in Pythons scikit-learn. This course guides you through algorithms to capture, store, and structure data streams coming from the web. You’ll explore recommendation engines and dive into classification via statistical algorithms, neural networks, and deep learning."
2,"Data Science Algorithms in a Week - Machine learning applications are highly automated and self-modifying, and they continue to improve over time with minimal human intervention as they learn with more data. To address the complex nature of various real-world data problems, specialized machine learning algorithms have been developed that solve these problems perfectly. Data science helps you gain new knowledge from existing data through algorithmic and statistical analysis. This course will address the problems related to accurate and efficient data classification and prediction. Over the course of 7 days, you will be introduced to seven algorithms, along with exercises that will help you learn different aspects of machine learning. You will see how to pre-cluster your data to optimize and classify it for large datasets. You will then find out how to predict data based on the existing trends in your datasets. This course covers algorithms such as: k-Nearest Neighbors, Naive Bayes, Decision Trees, Random Forest, k-Means, Regression, and Time-series. On completion of the book, you will understand which machine learning algorithm to pick for clustering, classification, or regression and which is best suited for your problem. Learn to use machine learning algorithms in a period of just 7 days"
3,"Jupyter for Data Science - Jupyter Notebook is a web-based environment that enables interactive computing in notebook documents. It allows you to create documents that contain live code, equations, and visualizations. This book is a comprehensive guide to getting started with data science using the popular Jupyter notebook. If you are familiar with Jupyter notebook and want to learn how to use its capabilities to perform various data science tasks, this is the book for you! From data exploration to visualization, this book will take you through every step of the way in implementing an effective data science pipeline using Jupyter. You will also see how you can utilize Jupyter's features to share your documents and codes with your colleagues. The book also explains how Python 3, R, and Julia can be integrated with Jupyter for various data science tasks. By the end of this book, you will comfortably leverage the power of Jupyter to perform various tasks in data science successfully."
4,"Machine Learning with R Cookbook- Big data has become a popular buzzword across many industries. An increasing number of people have been exposed to the term and are looking at how to leverage big data in their own businesses, to improve sales and profitability. However, collecting, aggregating, and visualizing data is just one part of the equation. Being able to extract useful information from data is another task, and a much more challenging one. Machine Learning with R Cookbook, Second Edition uses a practical approach to teach you how to perform machine learning with R. Each chapter is divided into several simple recipes. Through the step-by-step instructions provided in each recipe, you will be able to construct a predictive model by using a variety of machine learning packages. In this book, you will first learn to set up the R environment and use simple R commands to explore data. The next topic covers how to perform statistical analysis with machine learning analysis and assess created models, covered in detail later on in the book. You'll also learn how to integrate R and Hadoop to create a big data analysis platform. The detailed illustrations provide all the information required to start applying machine learning to individual projects. With Machine Learning with R Cookbook, machine learning has never been easier."
5,"Machine Learning Cookbook- Machine learning has become the new black. The challenge in today’s world is the explosion of data from existing legacy data and incoming new structured and unstructured data. The complexity of discovering, understanding, performing analysis, and predicting outcomes on the data using machine learning algorithms is a challenge. This cookbook will help solve everyday challenges you face as a data scientist. The application of various data science techniques and on multiple data sets based on real-world challenges you face will help you appreciate a variety of techniques used in various situations. The first half of the course provides recipes on fairly complex machine-learning systems, where you’ll learn to explore new areas of applications of machine learning and improve its efficiency. That includes recipes on classifications, neural networks, unsupervised and supervised learning, deep learning, reinforcement learning, and more. The second half of the course focuses on three different machine learning case studies, all based on real-world data, and offers solutions and solves specific machine-learning issues in each one."
6,"Beginning Data Science with Python and Jupyter- Get to grips with the skills you need for entry-level data science in this hands-on Python and Jupyter course. You'll learn about some of the most commonly used libraries that are part of the Anaconda distribution, and then explore machine learning models with real datasets to give you the skills and exposure you need for the real world. We'll finish up by showing you how easy it can be to scrape and gather your own data from the open web, so that you can apply your new skills in an actionable context."
7,"Practical Data Science Cookbook- As increasing amounts of data are generated each year, the need to analyze and create value out of it is more important than ever. Companies that know what to do with their data and how to do it well will have a competitive advantage over companies that don’t. Because of this, there will be an increasing demand for people that possess both the analytical and technical abilities to extract valuable insights from data and create valuable solutions that put those insights to use. Starting with the basics, this course covers how to set up your numerical programming environment, introduces you to the data science pipeline, and guides you through several data projects in a step-by-step format. By sequentially working through the steps in each lesson, you will quickly familiarize yourself with the process and learn how to apply it to a variety of situations with examples using the two most popular programming languages for data analysis—R and Python."
8,"Java for Data Science- Java is the most popular programming language, according to the TIOBE index, and it is a typical choice for running production systems in many companies, both in the startup world and among large enterprises. Not surprisingly, it is also a common choice for creating data science applications: it is fast and has a great set of data processing tools, both built-in and external. What is more, choosing Java for data science allows you to easily integrate solutions with existing software, and bring data science into production with less effort. This course will teach you how to create data science applications with Java. First, we will revise the most important things when starting a data science application, and then brush up the basics of Java and machine learning before diving into more advanced topics. We start by going over the existing libraries for data processing and libraries with machine learning algorithms. After that, we cover topics such as classification and regression, dimensionality reduction and clustering, information retrieval and natural language processing, and deep learning and big data. Finally, we finish the course by talking about the ways to deploy the model and evaluate it in production settings."
9,"Python Social Media Analytics- Social Media platforms such as Facebook, Twitter, Forums, Pinterest, and YouTube have become part of everyday life in a big way. However, these complex and noisy data streams pose a potent challenge to everyone when it comes to harnessing them properly and benefiting from them. This book will introduce you to the concept of social media analytics, and how you can leverage its capabilities to empower your business. Right from acquiring data from various social networking sources such as Twitter, Facebook, YouTube, Pinterest, and social forums, you will see how to clean data and make it ready for analytical operations using various Python APIs. This book explains how to structure the clean data obtained and store in MongoDB using PyMongo. You will also perform web scraping and visualize data using Scrappy and Beautiful soup. Finally, you will be introduced to different techniques to perform analytics at scale for your social data on the cloud, using Python and Spark. By the end of this course, you will be able to utilize the power of Python to gain valuable insights from social media data and use them to enhance your business processes."
10,"Learning Social Media Analytics with R- The Internet has truly become humongous, especially with the rise of various forms of social media in the last decade, which give users a platform to express themselves and also communicate and collaborate with each other. This course will help the reader to understand the current social media landscape and to learn how analytics can be leveraged to derive insights from it. This data can be analyzed to gain valuable insights into the behavior and engagement of users, organizations, businesses, and brands. It will help readers frame business problems and solve them using social data. The course will also cover several practical real-world use cases on social media using R and its advanced packages to utilize data science methodologies such as sentiment analysis, topic modeling, text summarization, recommendation systems, social network analysis, classification, and clustering. This will enable readers to learn different hands-on approaches to obtain data from diverse social media sources such as Twitter and Facebook. It will also show readers how to establish detailed workflows to process, visualize, and analyze data to transform social data into actionable insights."
11,"Python for Finance- This course uses Python as its computational tool. Since Python is free, any school or organization can download and use it. This course is organized according to various finance subjects. In other words, the first edition focuses more on Python, while the this edition is truly trying to apply Python to finance. The course starts by explaining topics exclusively related to Python. Then we deal with critical parts of Python, explaining concepts such as time value of money stock and bond evaluations, capital asset pricing model, multi-factor models, time series analysis, portfolio theory, options and futures. This course will help us to learn or review the basics of quantitative finance and apply Python to solve various problems, such as estimating IBM’s market risk, running a Fama-French 3-factor, 5-factor, or Fama-French-Carhart 4 factor model, estimating the VaR of a 5-stock portfolio, estimating the optimal portfolio, and constructing the efficient frontier for a 20-stock portfolio with real-world stock, and with Monte Carlo Simulation. Later, we will also learn how to replicate the famous Black-Scholes-Merton option model and how to price exotic options such as the average price call option."
12,"Real-time Data Processing and Analytics- With the rise of Big Data, there is an increasing need to process large amounts of data continuously, with a shorter turnaround time. Real-time data processing involves continuous input, processing and output of data, with the condition that the time required for processing is as short as possible. This book covers the majority of the existing and evolving open source technology stack for real-time processing and analytics. You will get to know about all the real-time solution aspects, from the source to the presentation to persistence. Through this practical book, you’ll be equipped with a clear understanding of how to solve challenges on your own. We’ll cover topics such as how to set up components, basic executions, integrations, advanced use cases, alerts, and monitoring. You’ll be exposed to the popular tools used in real-time processing today such as Apache Spark, Apache Flink, and Storm. Finally, you will put your knowledge to practical use by implementing all of the techniques in the form of a practical, real-world use case. By the end of this book, you will have a solid understanding of all the aspects of real-time data processing and analytics, and will know how to deploy the solutions in production environments in the best possible manner."
13,"Apache Spark 2.x Machine Learning Cookbook- Machine learning aims to extract knowledge from data, relying on fundamental concepts in computer science, statistics, probability, and optimization. Learning about algorithms enables a wide range of applications, from everyday tasks such as product recommendations and spam filtering to cutting edge applications such as self-driving cars and personalized medicine. You will gain hands-on experience of applying these principles using Apache Spark, a resilient cluster computing system well suited for large-scale machine learning tasks. This book begins with a quick overview of setting up the necessary IDEs to facilitate the execution of code examples that will be covered in various chapters. It also highlights some key issues developers face while working with machine learning algorithms on the Spark platform. We progress by uncovering the various Spark APIs and the implementation of ML algorithms with developing classification systems, recommendation engines, text analytics, clustering, and learning systems. Toward the final chapters, we’ll focus on building high-end applications and explain various unsupervised methodologies and challenges to tackle when implementing with big data ML systems."
14,"Python Machine Learning Cookbook- This eagerly anticipated edition of the popular Python Machine Learning Cookbook will enable you to adopt a fresh approach to dealing with real-world machine learning and deep learning tasks. With the help of over 100 recipes, you will learn to build powerful machine learning applications using modern libraries from the Python ecosystem. The course will also guide you on how to implement various machine learning algorithms for classification, clustering, and recommendation engines, using a recipe-based approach. With emphasis on practical solutions, dedicated sections in the course will help you to apply supervised and unsupervised learning techniques to real-world problems. Toward the concluding lessons, you will get to grips with recipes that teach you advanced techniques including reinforcement learning, deep neural networks, and automated machine learning. By the end of this course, you will be equipped with the skills you need to apply machine learning techniques and leverage the full capabilities of the Python ecosystem through real-world examples."
15,"TensorFlow Machine Learning Cookbook- TensorFlow is an open source software library for Machine Intelligence. The independent recipes in this course will teach you how to use TensorFlow for complex data computations and allow you to dig deeper and gain more insights into your data than ever before. With the help of this course, you will work with recipes for training models, model evaluation, sentiment analysis, regression analysis, clustering analysis, artificial neural networks, and more. You will explore RNNs, CNNs, GANs, reinforcement learning, and capsule networks, each using Google's machine learning library, TensorFlow. Through real-world examples, you will get hands-on experience with linear regression techniques with TensorFlow. Once you are familiar and comfortable with the TensorFlow ecosystem, you will be shown how to take it to production. By the end of the course, you will be proficient in the field of machine intelligence using TensorFlow. You will also have good insight into deep learning and be capable of implementing machine learning algorithms in real-world scenarios."
16,"R Machine Learning Projects- R is one of the most popular languages when it comes to performing computational statistics (statistical computing) easily and exploring the mathematical side of machine learning. With this course, you will leverage the R ecosystem to build efficient machine learning applications that carry out intelligent tasks within your organization. This course will help you test your knowledge and skills, guiding you on how to build easily through to complex machine learning projects. You will first learn how to build powerful machine learning models with ensembles to predict employee attrition. Next, you’ll implement a joke recommendation engine and learn how to perform sentiment analysis on Amazon reviews. You’ll also explore different clustering techniques to segment customers using wholesale data. In addition to this, the course will get you acquainted with credit card fraud detection using autoencoders, and reinforcement learning to make predictions and win on a casino slot machine. By the end of the course, you will be equipped to confidently perform complex tasks to build research and commercial projects for automated operations."
17,"Large Scale Machine Learning with Python- Large Python machine learning projects involve new problems associated with specialized machine learning architectures and designs that many data scientists have yet to tackle. But finding algorithms and designing and building platforms that deal with large sets of data is a growing need. Data scientists have to manage and maintain increasingly complex data projects, and with the rise of big data comes an increasing demand for computational and algorithmic efficiency. Large Scale Machine Learning with Python uncovers a new wave of machine learning algorithms that meet scalability demands together with a high predictive accuracy. Dive into scalable machine learning and the three forms of scalability. Speed up algorithms that can be used on a desktop computer with tips on parallelization and memory allocation. Get to grips with new algorithms that are specifically designed for large projects and can handle bigger files, and learn about machine learning in big data environments. We will also cover the most effective machine learning techniques on a map reduce framework in Hadoop and Spark in Python."
18,"Exploratory Analysis with pandas- The pandas is a Python library that lets you manipulate, transform, and analyze data. It is a popular framework for exploratory data visualization and analyzing datasets and data pipelines based on their properties. This course will be your practical guide to exploring datasets using pandas. You will start by setting up Python, pandas, and Jupyter Notebooks. You will learn how to use Jupyter Notebooks to run Python code. We then show you how to get data into pandas and do some exploratory analysis, before learning how to manipulate and reshape data using pandas methods. You will also learn how to deal with missing data from your datasets, how to draw charts and plots using pandas and Matplotlib, and how to create some effective visualizations for your audience. Finally, you will wrapup your newly gained pandas knowledge by learning how to import data out of pandas into some popular file formats. By the end of this course, you will have a better understanding of exploratory analysis and how to build exploratory data pipelines with Python."
19,"Integrating Hadoop- In today’s time, data with value is branched off into numerous databases across multiple companies. The challenge is bringing the data together. Integrating Hadoop shows how Hadoop is used to collect and load the data on physical devices and the cloud. The book begins with an introduction of Hadoop and the types of data fit for it. Next, it focuses on assembling the integration team and gives an overview of workloads in the organization. You will also identify data sources for Hadoop, such as No SQL Databases and Legacy/Relational Databases, distinguish between ETL and ELT, and learn how to load and unload data into Hadoop. You will also practice managing big data using methods such as Upserts and Use HBase, and discover the advantages of real-time computing and the basic structure of streaming data architecture. Finally, you will interact with the master data of an organization and learn the top 10 mistakes people commit while integrating Hadoop data and how to avoid them."
20,"Machine Learning Solutions- Machine learning (ML) helps you find hidden insights from your data without the need for explicit programming. This course is your key to solving any kind of ML problem you might come across in your job. You’ll encounter a set of simple to complex problems while building ML models, and you'll not only resolve these problems, but you’ll also learn how to build projects based on each problem, with a practical approach and easy-to-follow examples. The course includes a wide range of applications: from analytics and NLP, to computer vision domains. Some of the applications you will be working on include stock price prediction, a recommendation engine, building a chat-bot, a facial expression recognition system, and many more. The problem examples we cover include identifying the right algorithm for your dataset and use cases, creating and labeling datasets, getting enough clean data to carry out processing, identifying outliers, overftting datasets, hyperparameter tuning, and more. Here, you'll also learn to make more timely and accurate predictions. In addition, you'll deal with more advanced use cases, such as building a gaming bot, building an extractive summarization tool for medical documents, and you'll also tackle the problems faced while building an ML model. By the end of this course, you'll be able to fine-tune your models as per your needs to deliver maximum productivity."
21,"Turning Text into Gold: Taxonomies and Textual Analytics- With businesses operating round the clock, a large amount of data gets generated. This data can be efficiently converted into useful knowledge that can take your business to a higher level. This course introduces you to the concept of taxonomies and how they are used to simplify and understand the text. You'll explore how to use taxonomies for textual analytics. It begins with a quick history of taxonomies and their earliest usage. You’ll learn about the different types of taxonomies (recursive, networked, hierarchical, and so on. You'll also learn about ontologies and understand how the ontology becomes a bridge between the worlds of technology and business and commerce. The later lessons of the course show how to find the taxonomies that you need for successful textual analytics, update your taxonomies to include the constantly-changing language, and extract meaningful information from raw text using different tools, such as textual disambiguation, document fracturing, and so on. By the end of this course, you’ll be able to utilize the various aspects of taxonomies for efficient textual analysis."
22,"Keras 2.x Projects- Keras 2.x Projects explains how to leverage the power of Keras to build and train state-of-the-art deep learning models through a series of practical projects that look at a range of real-world application areas. To begin with, you will quickly set up a deep learning environment by installing the Keras library. Through each of the projects, you will explore and learn the advanced concepts of deep learning and will learn how to compute and run your deep learning models using the advanced offerings of Keras. You will train fully-connected multilayer networks, convolutional neural networks, recurrent neural networks, autoencoders and generative adversarial networks using real-world training datasets. The projects you will undertake are all based on real-world scenarios of all complexity levels, covering topics such as language recognition, stock volatility, energy consumption prediction, faster object classification for self-driving vehicles, and more. By the end of this course, you will be well versed with deep learning and its implementation with Keras. You will have all the knowledge you need to train your own deep learning models to solve different kinds of problems."
23,"Ensemble Machine Learning Cookbook- Ensemble modeling is an approach used to improve the performance of machine learning models. It combines two or more similar or dissimilar machine learning algorithms to deliver superior intellectual powers. This course will help you to implement popular machine learning algorithms to cover different paradigms of ensemble machine learning such as boosting, bagging, and stacking. The Ensemble Machine Learning Cookbook will start by getting you acquainted with the basics of ensemble techniques and exploratory data analysis. You'll then learn to implement tasks related to statistical and machine learning algorithms to understand the ensemble of multiple heterogeneous algorithms. It will also ensure that you don't miss out on key topics, such as like resampling methods. As you progress, you’ll get a better understanding of bagging, boosting, stacking, and working with the Random Forest algorithm using real-world examples. The course will highlight how these ensemble methods use multiple models to improve machine learning results, as compared to a single model. In the concluding lessons, you'll delve into advanced ensemble models using neural networks, natural language processing, and more. You’ll also be able to implement models such as fraud detection, text categorization, and sentiment analysis. By the end of this course, you'll be able to harness ensemble techniques and the working mechanisms of machine learning algorithms to build intelligent models using individual recipes."
24,"Intelligent Mobile Projects with TensorFlow- As a developer, you always need to keep an eye out and be ready for what will be trending soon, while also focusing on what's trending currently. So, what's better than learning about the integration of the best of both worlds, the present and the future? Artificial Intelligence (AI) is widely regarded as the next big thing after mobile, and Google's TensorFlow is the leading open source machine learning framework, the hottest branch of AI. This course covers more than 10 complete iOS, Android, and Raspberry Pi apps powered by TensorFlow and built from scratch, running all kinds of cool TensorFlow models offline on-device: from computer vision, speech and language processing to generative adversarial networks and AlphaZero-like deep reinforcement learning. You’ll learn how to use or retrain existing TensorFlow models, build your own models, and develop intelligent mobile apps running those TensorFlow models. You'll learn how to quickly build such apps with step-by-step tutorials and how to avoid many pitfalls in the process with lots of hard-earned troubleshooting tips.."
25,"Jupyter Cookbook- Jupyter has garnered a strong interest in the data science community of late, as it makes common data processing and analysis tasks much simpler. This course is for data science professionals who want to master various tasks related to Jupyter to create efficient, easy-to-share, scientific applications. The course starts with recipes on installing and running the Jupyter Notebook system on various platforms and configuring the various packages that can be used with it. You will then see how you can implement different programming languages and frameworks, such as Python, R, Julia, JavaScript, Scala, and Spark on your Jupyter Notebook. This course contains intuitive recipes on building interactive widgets to manipulate and visualize data in real time, sharing your code, creating a multi-user environment, and organizing your notebook. You will then get hands-on experience with Jupyter Labs, microservices, and deploying them on the web. By the end of this course, you will have taken your knowledge of Jupyter to the next level to perform all key tasks associated with it."
26,"Machine Learning for Algorithmic Trading- The explosive growth of digital data has boosted the demand for expertise in trading strategies that use machine learning (ML). This course enables you to use a broad range of supervised and unsupervised algorithms to extract signals from a wide variety of data sources and create powerful investment strategies. This course shows how to access market, fundamental, and alternative data via API or web scraping and offers a framework to evaluate alternative data. You’ll practice the ML workﬂow from model design, loss metric definition, and parameter tuning to performance evaluation in a time series context. You will understand ML algorithms such as Bayesian and ensemble methods and manifold learning, and will know how to train and tune these models using pandas, statsmodels, sklearn, PyMC3, xgboost, lightgbm, and catboost. This course also teaches you how to extract features from text data using spaCy, classify news and assign sentiment scores, and to use gensim to model topics and learn word embeddings from financial reports. You will also build and evaluate neural networks, including RNNs and CNNs, using Keras and PyTorch to exploit unstructured data for sophisticated strategies. Finally, you will apply transfer learning to satellite images to predict economic activity and use reinforcement learning to build agents that learn to trade in the OpenAI Gym."
27,"Machine Learning with the Elastic Stack- Machine Learning with the Elastic Stack is a comprehensive overview of the embedded commercial features of anomaly detection and forecasting. The course starts with installing and setting up Elastic Stack. You will perform time series analysis on varied kinds of data, such as log files, network flows, application metrics, and financial data. As you progress through the lessons, you will deploy machine learning within the Elastic Stack for logging, security, and metrics. In the concluding lessons, you will see how machine learning jobs can be automatically distributed and managed across the Elasticsearch cluster and made resilient to failure. By the end of this course, you will understand the performance aspects of incorporating machine learning within the Elastic ecosystem and create anomaly detection jobs and view results from Kibana directly."
28,"Python Machine Learning Blueprints- Machine learning is transforming the way we understand and interact with the world around us. This course is the perfect guide for you to put your knowledge and skills into practice and use the Python ecosystem to cover key domains in machine learning. This edition covers a range of libraries from the Python ecosystem, including TensorFlow and Keras, to help you implement real-world machine learning projects. The course begins by giving you an overview of machine learning with Python. With the help of complex datasets and optimized techniques, you’ll go on to understand how to apply advanced concepts and popular machine learning algorithms to real-world projects. Next, you’ll cover projects from domains such as predictive analytics to analyze the stock market and recommendation systems for GitHub repositories. In addition to this, you’ll also work on projects from the NLP domain to create a custom news feed using frameworks such as scikit-learn, TensorFlow, and Keras. Following this, you’ll learn how to build an advanced chatbot, and scale things up using PySpark. In the concluding lessons, you can look forward to exciting insights into deep learning and you'll even create an application using computer vision and neural networks. By the end of this course, you’ll be able to analyze data seamlessly and make a powerful impact through your projects."
29,"Machine Learning for Mobile- Machine learning presents an entirely unique opportunity in software development. It allows smartphones to produce an enormous amount of useful data that can be mined, analyzed, and used to make predictions. This course will help you master machine learning for mobile devices with easy-to-follow, practical examples. You will begin with an introduction to machine learning on mobiles and grasp the fundamentals so you become well-acquainted with the subject. You will master supervised and unsupervised learning algorithms, and then learn how to build a machine learning model using mobile-based libraries such as Core ML, TensorFlow Lite, ML Kit, and Fritz on Android and iOS platforms. In doing so, you will also tackle some common and not-so-common machine learning problems with regard to Computer Vision and other real-world domains. By the end of this course, you will have explored machine learning in depth and implemented on-device machine learning with ease, thereby gaining a thorough understanding of how to run, create, and build real-time machine-learning applications on your mobile devices."
30,"Data Analysis and Business Modeling with Excel 2013- Data Analysis and Business Modeling with Excel 2013 is one of the easiest to use data analysis tools you will ever come across. Its simplicity and powerful features has made it the go to tool for all your data needs. Complex operations with Excel, such as creating charts and graphs, visualization, and analyzing data make it a great tool for managers, data scientists, financial data analysts, and those who work closely with data. Learning data analysis and will help you bring your data skills to the next level. This course starts by walking you through creating your own data and bringing data into Excel from various sources. You’ll learn the basics of SQL syntax and how to connect it to a Microsoft SQL Server Database using Excel’s data connection tools. You will discover how to spot bad data and strategies to clean that data to make it useful to you. Next, you'll learn to create custom columns, identify key metrics, and make decisions based on business rules. You’ll create macros using VBA and use Excel 2013’s shiny new macros. Finally, at the end of the course, you'll be provided with useful shortcuts and tips, enabling you to do efficient data analysis and business modeling with Excel 2013."
31,"Build a Career in Data Science- Build a Career in Data Science is your guide to landing your first data science job and developing into a valued senior employee. By following clear and simple instructions, you’ll learn to craft an amazing resume and ace your interviews. In this demanding, rapidly changing field, it can be challenging to keep projects on track, adapt to company needs, and manage tricky stakeholders. You’ll love the insights on how to handle expectations, deal with failures, and plan your career path in the stories from seasoned data scientists included in the course."
32,"Data Science Boot camp- Data Science Boot camp is a comprehensive set of challenging projects carefully designed to grow your data science skills from novice to master. Veteran data scientist Leonard Apeltsin sets 10 increasingly difficult exercises that test your abilities against the kind of problems you’d encounter in the real-world. As you solve each challenge, you’ll acquire and expand the data science and Python skills you’ll use as a professional data scientist. Ranging from text processing to machine learning, each project comes complete with a unique downloadable data set and a fully-explained step-by-step solution. Because these projects come from Dr. Apelstin’s vast experience, each solution highlights the most likely failure points along with practical advice for getting past unexpected pitfalls. When you wrap up these 10 awesome exercises, you’ll have a diverse relevant skill set that’s transferable to working in industry."
33,"Healthcare Analytics Made Simple- In recent years, machine learning technologies and analytics have been widely utilized across the healthcare sector. Healthcare Analytics Made Simple bridges the gap between practicing doctors and data scientists. It equips the data scientists’ work with healthcare data and allows them to gain better insight from this data in order to improve healthcare outcomes. This course is a complete overview of machine learning for healthcare analytics, briefly describing the current healthcare landscape, machine learning algorithms, and Python and SQL programming languages. The step-by-step instructions teach you how to obtain real healthcare data and perform descriptive, predictive, and prescriptive analytics using popular Python packages such as pandas and scikit-learn. The latest research results in disease detection and healthcare image analysis are reviewed."
34,"Machine Learning for Healthcare Analytics Projects- Machine Learning (ML) has changed the way organizations and individuals use data to improve the efficiency of a system. ML algorithms allow strategists to deal with a variety of structured, unstructured, and semi-structured data. Machine Learning for Healthcare Analytics Projects is packed with new approaches and methodologies for creating powerful solutions for healthcare analytics. This course will teach you how to implement key machine learning algorithms and walk you through their use cases by employing a range of libraries from the Python ecosystem. You will build five end-to-end projects to evaluate the efficiency of Artificial Intelligence (AI) applications for carrying out simple-to-complex healthcare analytics tasks. With each project, you will gain new insights, which will then help you handle healthcare data efficiently. As you make your way through the course, you will use ML to detect cancer in a set of patients using support vector machines (SVMs) and k-Nearest neighbors (KNN) models. In the final lessons, you will create a deep neural network in Keras to predict the onset of diabetes in a huge dataset of patients. You will also learn how to predict heart diseases using neural networks."
35,"Machine Learning for Finance- Machine Learning for Finance explores new advances in machine learning and shows how they can be applied across the financial sector, including insurance, transactions, and lending. This course explains the concepts and algorithms behind the main machine learning techniques and provides example Python code for implementing the models yourself. The course is based on Jannes Klaas’ experience of running machine learning training courses for financial professionals. Rather than providing ready-made financial algorithms, the course focuses on advanced machine learning concepts and ideas that can be applied in a wide variety of ways. The course systematically explains how machine learning works on structured data, text, images, and time series. You'll cover generative adversarial learning, reinforcement learning, debugging, and launching machine learning products. Later lessons will discuss how to fight bias in machine learning. The course ends with an exploration of Bayesian inference and probabilistic programming."
36,"Go Machine Learning Projects- Go is the perfect language for machine learning; it helps to clearly describe complex algorithms, and also helps developers to understand how to run efficient optimized code. This course will teach you how to implement machine learning in Go to make programs that are easy to deploy and code that is not only easy to understand and debug, but also to have its performance measured. The course begins by guiding you through setting up your machine learning environment with Go libraries and capabilities. You will then plunge into regression analysis of a real-life house pricing dataset and build a classification model in Go to classify emails as spam or ham. Using Gonum, Gorgonia, and STL, you will explore time series analysis along with decomposition and clean up your personal Twitter timeline by clustering tweets. In addition to this, you will learn how to recognize handwriting using neural networks and convolutional neural networks. Lastly, you'll learn how to choose the most appropriate machine learning algorithms to use for your projects with the help of a facial detection project. By the end of this course, you will have developed a solid machine learning mindset, a strong hold on the powerful Go toolkit, and a sound understanding of the practical implementations of machine learning algorithms in real-world projects."
37,"Machine Learning Projects for Mobile Applications- Machine learning is a technique that focuses on developing computer programs that can be modified when exposed to new data. We can make use of it for our mobile applications and this course will show you how to do so. The course starts with the basics of machine learning concepts for mobile applications and how to get well equipped for further tasks. You will start by developing an app to classify age and gender using Core ML and Tensorflow Lite. You will explore neural style transfer and get familiar with how deep CNNs work. We will also take a closer look at Google’s ML Kit for the Firebase SDK for mobile applications. You will learn how to detect handwritten text on mobile. You will also learn how to create your own Snapchat filter by making use of facial attributes and OpenCV. You will learn how to train your own food classification model on your mobile; all of this will be done with the help of deep learning techniques. Lastly, you will build an image classifier on your mobile, compare its performance, and analyze the results on both mobile and cloud using TensorFlow Lite with an RCNN. By the end of this course, you will not only have mastered the concepts of machine learning but also learned how to resolve problems faced while building powerful apps on mobiles using TensorFlow Lite, Caffe2, and Core ML."
38,"IoT Solutions with Blockchain- Blockchain has been the hot topic of late thanks to cryptocurrencies. To make matters more interesting, the financial market is looking for ways to reduce operational costs and generate new business models, and this is where blockchain solutions come into the picture. In addition to this, with Internet of Things (IoT) trending and Arduino, Raspberry Pi, and other devices flooding the market, you can now create cheap devices even at home. Hands-On IoT Solutions with Blockchain starts with an overview of IoT concepts in the current business scenario. It then helps you develop your own device on the IBM Watson IoT platform and create your first IoT solution using Watson and Intel Edison. Once you are familiar with IoT, you will learn about Blockchain technology and its use cases. You will also work with the Hyperledger framework and develop your own Blockchain network. As you progress through the lesson, you'll work with problem statements and learn how to design your solution architecture so that you can create your own integrated Blockchain and IoT solution."
39,"Music Generation with Magenta- The importance of machine learning (ML) in art is growing at a rapid pace due to recent advancements in the field, and Magenta is at the forefront of this innovation. With this course, you’ll follow a hands-on approach to using ML models for music generation, learning how to integrate them into an existing music production workflow. Complete with practical examples and explanations of the theoretical background required to understand the underlying technologies, this course is the perfect starting point to begin exploring music generation. The course will help you learn how to use the models in Magenta for generating percussion sequences, monophonic and polyphonic melodies in MIDI, and instrument sounds in raw audio. Through practical examples and in-depth explanations, you’ll understand ML models such as RNNs, VAEs, and GANs. Using this knowledge, you’ll create and train your own models for advanced music generation use cases, along with preparing new datasets. Finally, you’ll get to grips with integrating Magenta with other technologies, such as digital audio workstations (DAWs), and using Magenta.js to distribute music generation apps in the browser.."
40,"Practical Recommender Systems- Are you envious when Amazon recommends its products or when Netflix is spot-on with a recommendation for a user? Then here’s your chance to learn how to add these skills to your repertoire. Reading this course will give you an understanding of what recommender systems are and how to apply them in practice. To make a recommender work, many things need to perform in concert. You need to understand how to collect data from your users and how to interpret it, and you need a toolbox of different recommender algorithms so you can choose the best one for your particular scenario. Most importantly, you need to understand how to evaluate whether your recommender system is doing its job well. All this and more is hidden within this course."
41,"Recommendation Systems with Python- Recommendation systems are at the heart of almost every internet business today; from Facebook to Netﬂix to Amazon. Providing good recommendations, whether it's friends, movies, or groceries, goes a long way in defining user experience and enticing your customers to use your platform. This course shows you how to do just that. You will learn about the different kinds of recommenders used in the industry and see how to build them from scratch using Python. No need to wade through tons of machine learning theory—you'll get started with building and learning about recommenders as quickly as possible. In this course, you will build an IMDB Top 250 clone, a content-based engine that works on movie metadata. You'll use collaborative filters to make use of customer behavior data, and a Hybrid Recommender that incorporates content based and collaborative filtering techniques"
42,"Natural Language Processing- Natural Language Processing is your guide to building machines that can read and interpret human language. In it, you’ll use readily available Python packages to capture the meaning in text and react accordingly. The course expands traditional NLP approaches to include neural networks, modern deep learning algorithms, and generative techniques as you tackle real-world problems like extracting dates and names, composing text, and answering free-form questions."
43,"Relevant Search- Relevant Search demystifies the subject and shows you that a search engine is a programmable relevance framework. You'll learn how to apply Elasticsearch or Solr to your business's unique ranking problems. The course demonstrates how to program relevance and how to incorporate secondary data sources, taxonomies, text analytics, and personalization. In practice, a relevance framework requires softer skills as well, such as collaborating with stakeholders to discover the right relevance requirements for your business. By the end, you?ll be able to achieve a virtuous cycle of provable, measurable relevance improvements over a search product?s lifetime."
44,"Think Like a Data Scientist- Think Like a Data Scientist teaches you a step-by-step approach to solving real-world data-centric problems. By breaking down carefully crafted examples, you'll learn to combine analytic, programming, and business perspectives into a repeatable process for extracting real knowledge from data. As you read, you'll discover (or remember) valuable statistical techniques and explore powerful data science software. More importantly, you'll put this knowledge together using a structured process for data science. When you've finished, you'll have a strong foundation for a lifetime of data science learning and practice."
45,"Real-World Machine Learning.- Real-World Machine Learning will teach you the concepts and techniques you need to be a successful machine learning practitioner without overdosing you on abstract theory and complex mathematics. By working through immediately relevant examples in Python, you’ll build skills in data acquisition and modeling, classification, and regression. You’ll also explore the most important tasks like model validation, optimization, scalability, and real-time streaming. When you’re done, you’ll be ready to successfully build, deploy, and maintain your own powerful ML systems."
46,"TensorFlow Machine Learning Projects- TensorFlow has transformed the way machine learning is perceived. TensorFlow Machine Learning Projects teaches you how to exploit the benefits—simplicity, efficiency, and flexibility—of using TensorFlow in various real-world projects. With the help of this course, you’ll not only learn how to build advanced projects using different datasets but also be able to tackle common challenges using a range of libraries from the TensorFlow ecosystem. To start with, you’ll get to grips with using TensorFlow for machine learning projects; you’ll explore a wide range of projects using TensorForest and TensorBoard for detecting exoplanets, TensorFlow.js for sentiment analysis, and TensorFlow Lite for digit classification. As you make your way through the course, you’ll build projects in various real-world domains, incorporating natural language processing (NLP), the Gaussian process, autoencoders, recommender systems, and Bayesian neural networks, along with trending areas such as Generative Adversarial Networks (GANs), capsule networks, and reinforcement learning. You’ll learn how to use the TensorFlow on Spark API and GPU-accelerated computing with TensorFlow to detect objects, followed by how to train and develop a recurrent neural network (RNN) model to generate book scripts. By the end of this course, you’ll have gained the required expertise to build full-fledged machine learning projects at work."
47,"Machine Learning to Detect Phishing Websites- In this course, you will be filling in the role of a data scientist employed by an organization’s cybersecurity manager. Lately, the employees of the organization are receiving a lot of emails containing links to phishing websites. Your task will be to develop a machine learning model for predicting whether or not an email that contains a link to a website is a phishing website or not. Phishing attacks are considered to be one of the most common types of online security threats, and are capable of breaking into an organization’s online security so as to extract confidential information like user passwords, financial information, and so on. The Internet Crime Report 2018 presents the effects of phishing websites."
48,"Monitoring Changes in Surface Water Using Satellite Image Data- In this, you’ll fill the shoes of a data scientist at UNESCO (United Nations Educational, Scientific and Cultural Organization). Your job involves assessing long-term changes to freshwater deposits, one of humanity’s most important resources. Recently, two European Space Agency satellites have given you a massive amount of new data in the form of satellite imagery. Your task is to build a deep learning algorithm that can process this data and automatically detect water pixels in the imagery of a region. To accomplish this, you will design, implement, and evaluate a convolutional neural network model for image pixel classification, or image segmentation. Your challenges will include compiling your data, training your model, evaluating its performance, and providing a summary of your findings to your superiors. Throughout, you’ll use the Google Collaboratory (“Colab”) coding environment to access free GPU computer resources and speed up your training times."
49,"Human Pose Estimation with Deep Neural Networks- In this course, you will learn about the building blocks of deep neural networks and how to use them. After this, you will be able to build basic image classification, image segmentation or key point detection algorithms yourself. You will also learn how to use and integrate more complex models, such as an object detector into your course. The building blocks of this course are also used in many other computer vision/machine applications. Object detection, for example, is also used for face recognition/detection, autonomous driving and OCR. The same algorithms used for key point detection are also used for image segmentation, facial landmark detection or action recognition. This course will give you the basic understanding of how all these algorithms work."
50,"Discovering Disease Outbreaks from News Headlines- In this course, you’ll take on the role of a data scientist at the World Health Organization (WHO). The WHO is responsible for responding to international epidemics, a critical component of which involves monitoring global news headlines for signs of disease outbreaks. However, this daily deluge of news data is too huge to manually analyze. Your challenge is to pull geographic information from headlines, and determine where in the world outbreaks are occurring. Problems you will have to solve include extracting information from text using regular expressions, using the Basemap Matplotlib extension to visualize map locations for patterns indicating an epidemic, and reporting your findings to your superiors so resources can be dispatched."
51,"Decoding Data Science Job Postings to Improve Your Resume- In this course, you’re a budding data scientist who has created a draft of your resume. You want to apply for data science jobs, but would like to find the jobs you have the best shot at so would like to optimize your resume for a better chance at getting one of these jobs. We will be using NLP and text analytics to search for the most relevant data science jobs from online job postings and optimize our resume for the job postings. The job post HTML pages have already been web-scraped, and we will be loading them into Python and processing the text data from there. The number of job postings that were collected is large (over one thousand), so we will need to process them with data science methods using Python. We will use text similarity methods to find the most similar job postings, and also to find key skills we’re missing from our resume. We’ll summarize our findings by printing out highlights of the text results, as well as displaying plots and word clouds of the data"
52,"Practical Data Science with R- Practical Data Science with R shows you how to apply the R programming language and useful statistical techniques to everyday business situations. Using examples from marketing, business intelligence, and decision support, it shows you how to design experiments (such as A/B tests), build predictive models, and present results to audiences of all levels."
53,"Building Domain Specific Language Models- In this course, you will be taking on the role of an NLP data scientist at Stack Exchange, a network of question-and-answer (Q&A) websites on topics in diverse fields. Stack Exchange has over 10M registered users and is best known for its flagship websites Stack Overflow or Ask Ubuntu. You will build statistics-focused language models using gradually more complex methods. You will evaluate and apply these models to the tasks of: Query completion Larger text generation Sentence selection
"
54,"3D Medical Image Analysis with PyTorch- In this course, you will be filling the role of a machine learning engineer/researcher at a healthcare technology company specializing in medical imaging applications. Your team wants to process and analyze magnetic resonance (MR) images of the brain. An MR imaging system is a flexible device that can create multiple types of images based on what a physician wants to see, but not all types of images are acquired in every scan due to time constraints. Your current processing and analysis algorithms require two types of MR images, but a new set of customer data only has one of those types. However, you have access to a fairly large, preprocessed dataset of paired examples of the two types of MR images, and you decide that deep learning would best perform this type of image transformation task."
55,"Growth Hacking with NLP and Sentiment Analysis- In this course, you’ll step into the role of a Natural Language Processing Specialist working in the Growth Hacking Team of a new video game startup. Your team wants to massively accelerate your company’s early growth by acquiring huge numbers of customers at the lowest possible cost. To help tailor marketing messages, your boss has asked you to map the market and find out how customers evaluate your competitors’ products. Your challenge is to create a sentiment analyzer that will give a deeper understanding of customer feedback and opinions. To do this, you’ll need to download and create a dataset from Amazon reviews, build an algorithm that will determine whether a review is positive or negative, evaluate your analyzer's performance against star ratings, and lay out your findings in a report for your manager."
56,"Collective Intelligence- In the Web 2.0 era, leveraging the collective power of user contributions, interactions, and feedback is the key to market dominance. A new category of powerful programming techniques lets you discover the patterns, inter-relationships, and individual profiles—the collective intelligence—locked in the data people leave behind as they surf websites, post blogs, and interact with other users.Collective Intelligence is a course for implementing collective-intelligence concepts using Java. It is the first Java-based course to emphasize the underlying algorithms and technical implementation of vital data gathering and mining techniques like analyzing trends, discovering relationships, and making predictions. It provides a pragmatic approach to personalization by combining content-based analysis with collaborative approaches."
57,"Scikit-learn Cookbook- Python is quickly becoming the go-to language for analysts and data scientists due to its simplicity and flexibility, and within the Python data space, scikit-learn is the unequivocal choice for machine learning. This course includes walk throughs and solutions to the common as well as the not-so-common problems in machine learning, and how scikit-learn can be leveraged to perform various machine learning tasks effectively. The edition begins with taking you through recipes on evaluating the statistical properties of data and generates synthetic data for machine learning modelling. As you progress through the lessons, you will comes across recipes that will teach you to implement techniques like data pre-processing, linear regression, logistic regression, K-NN, Naïve Bayes, classification, decision trees, Ensembles and much more. Furthermore, you’ll learn to optimize your models with multi-class classification, cross validation, model evaluation and dive deeper in to implementing deep learning with scikit-learn. Along with covering the enhanced features on model section, API and new features like classifiers, regressors and estimators the lesson also contains recipes on evaluating and fine-tuning the performance of your model. By the end of this course, you will have explored plethora of features offered by scikit-learn for Python to solve any machine learning problem you come across."
58,"Building Machine Learning Systems with Python- Machine learning allows systems to learn things without being explicitly programmed to do so. Python is one of the most popular languages used to develop machine learning applications, which take advantage of its extensive library support. This third edition of Building Machine Learning Systems with Python addresses recent developments in the field by covering the most-used datasets and libraries to help you build practical machine learning systems. Using machine learning to gain deeper insights from data is a key skill required by modern application developers and analysts alike. Python, being a dynamic language, allows for fast exploration and experimentation. This lesson shows you exactly how to find patterns in your raw data. You will start by brushing up on your Python machine learning knowledge and being introduced to libraries. You'll quickly get to grips with serious, real-world projects on datasets, using modeling and creating recommendation systems. With Building Machine Learning Systems with Python, you’ll gain the tools and understanding required to build your own systems, all tailored to solve real-world data analysis problems. By the end of this lesson, you will be able to build machine learning systems using techniques and methodologies such as classification, sentiment analysis, computer vision, reinforcement learning, and neural networks."
59,"SAS for Finance- SAS is a groundbreaking tool for advanced predictive and statistical analytics used by top banks and financial corporations to establish insights from their financial data. SAS for Finance offers you the opportunity to leverage the power of SAS analytics in redefining your data. Packed with real-world examples from leading financial institutions, the author discusses statistical models using time series data to resolve business issues. This lesson shows you how to exploit the capabilities of this high-powered package to create clean, accurate financial models. You can easily assess the pros and cons of models to suit your unique business needs. By the end of this lesson, you will be able to leverage the true power of SAS to design and develop accurate analytical models to gain deeper insights into your financial data."
60,"R- R teaches you how to use the R language by presenting examples relevant to scientific, technical, and business developers. Focusing on practical solutions, the course offers a crash course in statistics, including elegant methods for dealing with messy and incomplete data. You'll also master R's extensive graphical capabilities for exploring and presenting data visually. And this expanded includes new lessons on forecasting, data mining, and dynamic report writing. Working in a hands-on learning environment, led by our R expert instructor, students will learn about and explore:
Focusing on practical solutions, offers a crash course in statistics and covers elegant methods for dealing with messy and incomplete data that are difficult to analyze using traditional methods. 
You'll also master R's extensive graphical capabilities for exploring and presenting data visually. 
this expanded edition includes new lessons on time series analysis, cluster analysis, and classification methodologies, including decision trees, random forests, and support vector machines.
"
61,"Mahout- This course covers machine learning using Apache Mahout. Based on experience with real-world applications, it introduces practical use cases and illustrates how Mahout can be applied to solve them. It places particular focus on issues of scalability and how to apply these techniques against large data sets using the Apache Hadoop framework."
62,"Machine Learning on AWS- AWS is constantly driving new innovations that empower data scientists to explore a variety of machine learning (ML) cloud services. This course is your comprehensive reference for learning and implementing advanced ML algorithms in AWS cloud. As you go through the lessons, you’ll gain insights into how these algorithms can be trained, tuned, and deployed in AWS using Apache Spark on Elastic Map Reduce (EMR), SageMaker, and TensorFlow. While you focus on algorithms such as XGBoost, linear models, factorization machines, and deep nets, the course will also provide you with an overview of AWS as well as detailed practical applications that will help you solve real-world problems. Every practical application includes a series of companion notebooks with all the necessary code to run on AWS. In the next few lessons, you will learn to use SageMaker and EMR Notebooks to perform a range of tasks, right from smart analytics and predictive modeling through to sentiment analysis. By the end of this course, you will be equipped with the skills you need to effectively handle machine learning projects and implement and evaluate algorithms on AWS"
63,"Machine Learning for Developers- Most of us have heard about the term Machine Learning, but surprisingly the question frequently asked by developers across the globe is, “How do I get started in Machine Learning?”. One reason could be attributed to the vastness of the subject area because people often get overwhelmed by the abstractness of ML and terms such as regression, supervised learning, probability density function, and so on. This book is a systematic guide teaching you how to implement various Machine Learning techniques and their day-to-day application and development. You will start with the very basics of data and mathematical models in easy-to-follow language that you are familiar with; you will feel at home while implementing the examples. The course will introduce you to various libraries and frameworks used in the world of Machine Learning, and then, without wasting any time, you will get to the point and implement Regression, Clustering, classification, Neural networks, and more with fun examples. As you get to grips with the techniques, you’ll learn to implement those concepts to solve real-world scenarios for ML applications such as image analysis, Natural Language processing, and anomaly detections of time series data. By the end of the course, you will have learned various ML techniques to develop more efficient and intelligent applications."
64,"Machine Learning with IBM Watson- IBM Cloud is a collection of cloud computing services for data analytics using machine learning and artificial intelligence (AI). This course is a complete guide to help you become well versed with machine learning on the IBM Cloud using Python. Machine Learning with IBM Watson starts with supervised and unsupervised machine learning concepts, in addition to providing you with an overview of IBM Cloud and Watson Machine Learning. You'll gain insights into running various techniques, such as K-means clustering, K-nearest neighbor (KNN), and time series prediction in IBM Cloud with real-world examples. The course will then help you delve into creating a Spark pipeline in Watson Studio. You will also be guided through deep learning and neural network principles on the IBM Cloud using TensorFlow. With the help of NLP techniques, you can then brush up on building a chatbot. In later lessons, you will cover three powerful case studies, including the facial expression classification platform, the automated classification of lithofacies, and the multi-biometric identity authentication platform, helping you to become well versed with these methodologies. By the end of this course, you will be ready to build efficient machine learning solutions on the IBM Cloud and draw insights from the data at hand using real-world examples."
65,"Scala for Machine Learning- The discovery of information through data clustering and classification is becoming a key differentiator for competitive organizations. Machine learning applications are everywhere, from self-driving cars, engineering design, logistics, manufacturing, and trading strategies, to detection of genetic anomalies. The course is your one stop guide that introduces you to the functional capabilities of the Scala programming language that are critical to the creation of machine learning algorithms such as dependency injection and implicits. You start by learning data preprocessing and filtering techniques. Following this, you'll move on to unsupervised learning techniques such as clustering and dimension reduction, followed by probabilistic graphical models such as Naïve Bayes, hidden Markov models and Monte Carlo inference. Further, it covers the discriminative algorithms such as linear, logistic regression with regularization, kernelization, support vector machines, neural networks, and deep learning. You’ll move on to evolutionary computing, multibandit algorithms, and reinforcement learning. Finally, the course includes a comprehensive overview of parallel computing in Scala and Akka followed by a description of Apache Spark and its ML library. With updated codes based on the latest version of Scala and comprehensive examples, this book will ensure that you have more than just a solid fundamental knowledge in machine learning with Scala."
66,"Deep-Learning-for-Natural-Language-Processing- Deep Learning for Natural Language Processing teaches you to apply state-of-the-art deep learning approaches to natural language processing tasks. You’ll learn key NLP concepts like neural word embeddings, auto-encoders, part-of-speech tagging, parsing, and semantic inference. Then you’ll dive deeper into advanced topics including deep memory-based NLP, linguistic structure, and hyperparameters for deep NLP. Along the way, you’ll pick up emerging best practices and gain hands-on experience with a myriad of examples, all written in Python and the powerful Keras library. By the time you’re done reading this invaluable course, you’ll be solving a wide variety of NLP problems with cutting-edge deep learning techniques!"
67,"Ensemble Learning with R- Ensemble techniques are used for combining two or more similar or dissimilar machine learning algorithms to create a stronger model. Such a model delivers superior prediction power and can give your datasets a boost in accuracy. Ensemble Learning with R begins with the important statistical resampling methods. You will then walk through the central trilogy of ensemble techniques – bagging, random forest, and boosting – then you'll learn how they can be used to provide greater accuracy on large datasets using popular R packages. You will learn how to combine model predictions using different machine learning algorithms to build ensemble models. In addition to this, you will explore how to improve the performance of your ensemble models. By the end of this course, you will have learned how machine learning algorithms can be combined to reduce common problems and build simple efficient ensemble models with the help of real-world examples."
68,"Machine Learning with scikit-learn- Machine learning is the buzzword bringing computer science and statistics together to build smart and efficient models. Using powerful algorithms and techniques offered by machine learning you can automate any analytical model. This course examines a variety of machine learning models including popular machine learning algorithms such as k-nearest neighbors, logistic regression, naive Bayes, k-means, decision trees, and artificial neural networks. It discusses data preprocessing, hyperparameter optimization, and ensemble methods. You will build systems that classify documents, recognize images, detect ads, and more. You will learn to use scikit-learn’s API to extract features from categorical variables, text and images; evaluate model performance, and develop an intuition for how to improve your model’s performance. By the end of this course, you will master all required concepts of scikit-learn to build efficient models at work to carry out advanced tasks with the practical approach."
69,"Machine Learning for OpenCV- Machine Learning is no longer just a buzzword, it is all around us: from protecting your email, to automatically tagging friends in pictures, to predicting what movies you like. Computer vision is one of today's most exciting application fields of Machine Learning, with Deep Learning driving innovative systems such as self-driving cars and Google’s DeepMind. OpenCV lies at the intersection of these topics, providing a comprehensive open-source library for classic as well as state-of-the-art computer vision and Machine Learning algorithms. In combination with Python Anaconda, you will have access to all the open-source computing libraries you could possibly ask for. Machine Learning for OpenCV begins by introducing you to the essential concepts of statistical learning, such as classification and regression. Once all the basics are covered, you will start exploring various algorithms such as decision trees, support vector machines, and Bayesian networks, and learn how to combine them with other OpenCV functionality. As the course progresses, so will your Machine Learning skills, until you are ready to take on today's hottest topic in the field: Deep Learning. By the end of this, you will be ready to take on your own Machine Learning problems, either by building on the existing source code or developing your own algorithm from scratch!"
70,"Machine Learning for the Web- Python is a general purpose and also a comparatively easy to learn programming language. Hence it is the language of choice for data scientists to prototype, visualize, and run data analyses on small and medium-sized data sets. This is a unique course that helps bridge the gap between machine learning and web development. It focuses on the difficulties of implementing predictive analytics in web applications. We focus on the Python language, frameworks, tools, and libraries, showing you how to build a machine learning system. You will explore the core machine learning concepts and then develop and deploy the data into a web application using the Django framework. You will also learn to carry out web, document, and server mining tasks, and build recommendation engines. Later, you will explore Python’s impressive Django framework and will find out how to build a modern simple web app with machine learning features."
71,"Java Machine Learning- Java is one of the main languages used by practicing data scientists; much of the Hadoop ecosystem is Java-based, and it is certainly the language that most production systems in Data Science are written in. If you know Java, Mastering Machine Learning with Java is your next step on the path to becoming an advanced practitioner in Data Science. This course aims to introduce you to an array of advanced techniques in machine learning, including classification, clustering, anomaly detection, stream learning, active learning, semi-supervised learning, probabilistic graph modeling, text mining, deep learning, and big data batch and stream machine learning. Accompanying each lesson are illustrative examples and real-world case studies that show how to apply the newly learned techniques using sound methodologies and the best Java-based tools available today. On completing this course, you will understand the tools and techniques for building powerful machine learning models to solve data science problems in just about any domain."
72,"Predictive Analytics with R- R offers a free and open source environment that is perfect for both learning and deploying predictive modeling solutions. With its constantly growing community and plethora of packages, R offers the functionality to deal with a truly vast array of problems. The course begins with a dedicated chapter on the language of models and the predictive modeling process. You will understand the learning curve and the process of tidying data. Each subsequent chapter tackles a particular type of model, such as neural networks, and focuses on the three important questions of how the model works, how to use R to train it, and how to measure and assess its performance using real-world datasets. How do you train models that can handle really large datasets? This course will also show you just that. Finally, you will tackle the really important topic of deep learning by implementing applications on word embedding and recurrent neural networks. By the end of this course, you will have explored and tested the most popular modeling techniques in use on real- world datasets and mastered a diverse range of techniques in predictive analytics using R."
73,"Statistical Application Development with R and Python- Statistical Analysis involves collecting and examining data to describe the nature of data that needs to be analyzed. It helps you explore the relation of data and build models to make better decisions. This course explores statistical concepts along with R and Python, which are well integrated from the word go. Almost every concept has an R code going with it which exemplifies the strength of R and applications. The R code and programs have been further strengthened with equivalent Python programs. Thus, you will first understand the data characteristics, descriptive statistics and the exploratory attitude, which will give you firm footing of data analysis. Statistical inference will complete the technical footing of statistical methods. Regression, linear, logistic modeling, and CART, builds the essential toolkit. This will help you complete complex problems in the real world. You will begin with a brief understanding of the nature of data and end with modern and advanced statistical models like CART. Every step is taken with DATA and R code, and further enhanced by Python. The data analysis journey begins with exploratory analysis, which is more than simple, descriptive, data summaries. You will then apply linear regression modeling, and end with logistic regression, CART, and spatial statistics. By the end of this course you will be able to apply your statistical learning in major domains at work or in your projects."
74,"Learn Unity ML-Agents- Unity Machine Learning agents allow researchers and developers to create games and simulations using the Unity Editor, which serves as an environment where intelligent agents can be trained with machine learning methods through a simple-to-use Python API. This course takes you from the basics of Reinforcement and Q Learning to building Deep Recurrent Q-Network agents that cooperate or compete in a multi-agent ecosystem. You will start with the basics of Reinforcement Learning and how to apply it to problems. Then you will learn how to build self-learning advanced neural networks with Python and Keras/TensorFlow. From there you move o n to more advanced training scenarios where you will learn further innovative ways to train your network with A3C, imitation, and curriculum learning models. By the end of the course, you will have learned how to build more complex environments by building a cooperative and competitive multi-agent ecosystem."
75,"TensorFlow 2.0- TensorFlow is one of the most popular machine learning frameworks in Python. With this course, you will improve your knowledge of some of the latest TensorFlow features and will be able to perform supervised and unsupervised machine learning and also train neural networks. After giving you an overview of what's new in TensorFlow 2.0 Alpha, the course moves on to setting up your machine learning environment using the TensorFlow library. You will perform popular supervised machine learning tasks using techniques such as linear regression, logistic regression, and clustering. You will get familiar with unsupervised learning for autoencoder applications. The course will also show you how to train effective neural networks using straightforward examples in a variety of different domains. By the end of the course, you will have been exposed to a large variety of machine learning and neural network TensorFlow techniques."
76,"Deep Learning for Vision Systems- Deep Learning for Vision Systems teaches you to apply deep learning techniques to solve real-world computer vision problems. In his straightforward and accessible style, DL and CV expert Mohamed Elgendy introduces you to the concept of visual intuition—how a machine learns to understand what it sees. Then you’ll explore the DL algorithms used in different CV applications. You’ll drill down into the different parts of the CV interpreting system, or pipeline. Using Python, OpenCV, Keras, TensorFlow, and Amazon’s Mx Net, you’ll discover advanced DL techniques for solving CV problems. Applications of focus include image classification, segmentation, captioning, and generation as well as face recognition and analysis. You’ll also cover the most important deep learning architectures including artificial neural networks (ANNs), convolutional networks (CNNs), and recurrent networks (RNNs), knowledge that you can apply to related deep learning disciplines like natural language processing and voice user interface. Real-life, scalable projects from Amazon, Google, and Facebook drive it all home. With this invaluable course, you’ll gain the essential skills for building amazing end-to-end CV projects that solve real-world problems."
77,"Deep Learning with PyTorch- Deep Learning with PyTorch teaches you how to implement deep learning algorithms with Python and PyTorch. This course takes you into a fascinating case study: building an algorithm capable of detecting malignant lung tumors using CT scans. As the authors guide you through this real example, you'll discover just how effective and fun PyTorch can be. After a quick introduction to the deep learning landscape, you'll explore the use of pre-trained networks and start sharpening your skills on working with tensors. You'll find out how to represent the most common types of data with tensors and how to build and train neural networks from scratch on practical examples, focusing on images and sequences. After covering the basics, the course will take you on a journey through larger projects. The centerpiece of the course is a neural network designed for cancer detection. You'll discover ways for training networks with limited inputs and start processing data to get some results. You'll sift through the unreliable initial results and focus on how to diagnose and fix the problems in your neural network. Finally, you'll look at ways to improve your results by training with augmented data, make improvements to the model architecture, and perform other fine tuning.!"
78,"Training Systems using Python Statistical Modeling- Python's ease of use and multi-purpose nature has led it to become the choice of tool for many data scientists and machine learning developers today. Its rich libraries are widely used for data analysis, and more importantly, for building state-of-the-art predictive models. This course takes you through an exciting journey, of using these libraries to implement effective statistical models for predictive analytics. You’ll start by diving into classical statistical analysis, where you will learn to compute descriptive statistics using pandas. You will look at supervised learning, where you will explore the principles of machine learning and train different machine learning models from scratch. You will also work with binary prediction models, such as data classification using k-nearest neighbors, decision trees, and random forests. This course also covers algorithms for regression analysis, such as ridge and lasso regression, and their implementation in Python. You will also learn how neural networks can be trained and deployed for more accurate predictions, and which Python libraries can be used to implement them. By the end of this course, you will have all the knowledge you need to design, build, and deploy enterprise-grade statistical models for machine learning using Python and its rich ecosystem of libraries for predictive analytics."
79,"Deep Reinforcement Learning- Deep Reinforcement Learning is a beautifully balanced approach to teaching, offering numerous large and small examples, annotated diagrams and code, engaging exercises, and skillfully crafted writing. You'll explore, discover, and learn as you lock in the ins and outs of reinforcement learning, neural networks, and AI agents. You will go from small grid world environments and some of the foundational algorithms to some of the most challenging environments out there today and cutting-edge techniques to solve these environments."
80,"Applied Unsupervised Learning with R- Starting with the basics, Applied Unsupervised Learning with R explains clustering methods, distribution analysis, data encoders, and features of R that enable you to understand your data better and get answers to your most pressing business questions. This course begins with the most important and commonly used method for unsupervised learning - clustering - and explains the three main clustering algorithms - k-means, divisive, and agglomerative. Following this, you'll study market basket analysis, kernel density estimation, principal component analysis, and anomaly detection. You'll be introduced to these methods using code written in R, with further instructions on how to work with, edit, and improve R code. To help you gain a practical understanding, the course also features useful tips on applying these methods to real business problems, including market segmentation and fraud detection. By working through interesting activities, you'll explore data encoders and latent variable models. By the end of this course, you will have a better understanding of different anomaly detection methods, such as outlier detection, Mahalanobis distances, and contextual and collective anomaly detection."
81,"Essential Natural Language Processing- Essential Natural Language Processing is a hands-on guide to NLP with practical techniques you can put into action right away. By following the numerous Python-based examples and real-world case studies, you’ll apply NLP to search applications, extracting meaning from text, sentiment analysis, user profiling, and more. When you’re done, you’ll have a solid grounding in NLP that will serve as a foundation for further learning."
82,"GANs- GANs teaches you to build and train your own Generative Adversarial Networks. You’ll start by creating simple generator and discriminator networks that are the foundation of GAN architecture. Then, following numerous hands-on examples, you’ll train GANs to generate high-resolution images, image-to-image translation, and targeted data generation. Along the way, you’ll find pro tips for making your system smart, effective, and fast."
83,"Machine Learning with Apache Spark- Every person and every organization in the world manage data, whether they realize it or not. Data is used to describe the world around us and can be used for almost any purpose, from analyzing consumer habits to fighting disease and serious organized crime. Ultimately, we manage data in order to derive value from it, and many organizations around the world have traditionally invested in technology to help process their data faster and more efficiently. But we now live in an interconnected world driven by mass data creation and consumption where data is no longer rows and columns restricted to a spreadsheet, but an organic and evolving asset in its own right. With this realization comes major challenges for organizations: how do we manage the sheer size of data being created every second (think not only spreadsheets and databases, but also social media posts, images, videos, music, blogs and so on)? And once we can manage all of this data, how do we derive real value from it? The focus of Machine Learning with Apache Spark is to help us answer these questions in a hands-on manner. We introduce the latest scalable technologies to help us manage and process big data. We then introduce advanced analytical algorithms applied to real-world use cases in order to uncover patterns, derive actionable insights, and learn from this big data."
84,"Machine Learning with Core ML- Core ML is a popular framework by Apple, with APIs designed to support various machine learning tasks. It allows you to train your machine learning models and then integrate them into your iOS apps. Machine Learning with Core ML is a fun and practical guide that not only demystifies Core ML but also sheds light on machine learning. In this course, you’ll walk through realistic and interesting examples of machine learning in the context of mobile platforms (specifically iOS). You’ll learn to implement Core ML for visual-based applications using the principles of transfer learning and neural networks. Having got to grips with the basics, you’ll discover a series of seven examples, each providing a new use-case that uncovers how machine learning can be applied along with the related concepts. By the end of the course, you will have the skills required to put machine learning to work in their own applications, using the Core ML APIs"
85,"Python Machine Learning By Example- The surge in interest in machine learning (ML) is due to the fact that it revolutionizes automation by learning patterns in data and using them to make predictions and decisions. If you’re interested in ML, this course will serve as your entry point to ML. Python Machine Learning By Example begins with an introduction to important ML concepts and implementations using Python libraries. Each lesson of the course walks you through an industry adopted application. You’ll implement ML techniques in areas such as exploratory data analysis, feature engineering, and natural language processing (NLP) in a clear and easy-to-follow way. With the help of this extended and updated edition, you’ll understand how to tackle data-driven problems and implement your solutions with the powerful yet simple Python language and popular Python packages and tools such as TensorFlow, scikit-learn, gensim, and Keras. To aid your understanding of popular ML algorithms, the course covers interesting and easy-to-follow examples such as news topic modeling and classification, spam email detection, stock price forecasting, and more. By the end of the course, you’ll have put together a broad picture of the ML ecosystem and will be well-versed with the best practices of applying ML techniques to make the most out of new opportunities."
86,"Bayesian Analysis with Python- Bayesian Analysis with Python is an introduction to the main concepts of applied Bayesian inference and its practical implementation in Python using PyMC3, a state-of-the-art probabilistic programming library, and ArviZ, a new library for exploratory analysis of Bayesian models. The main concepts of Bayesian statistics are covered using a practical and computational approach. Synthetic and real data sets are used to introduce several types of models, such as generalized linear models for regression and classification, mixture models, hierarchical models, and Gaussian processes, among others. By the end of the course, you will have a working knowledge of probabilistic modeling and you will be able to design and implement Bayesian models for your own data science problems. After reading the course you will be better prepared to delve into more advanced material or specialized statistical modeling if you need to."
87,"Machine Learning for Data Mining- Machine learning (ML) combined with data mining can give you amazing results in your data mining work by empowering you with several ways to look at data. This course will help you improve your data mining techniques by using smart modeling techniques. This course will teach you how to implement ML algorithms and techniques in your data mining work. It will enable you to pair the best algorithms with the right tools and processes. You will learn how to identify patterns and make predictions with minimal human intervention. You will build different types of ML models, such as the neural network, the Support Vector Machines (SVMs), and the Decision tree. You will see how all these models works and what kind of data in the dataset they are suited for. You will learn how to combine the results of different models to improve accuracy. Topics such as removing noise and handling errors will give you an added edge in model building and optimization. By the end of this course, you will be able to build predictive models and extract information of interest from the dataset."
88,"Machine Learning With Go- This popular Machine Learning With Go shows you how to overcome the common challenges of integrating analysis and machine learning code within an existing engineering organization. Machine Learning With Go, , will begin by helping you gain an understanding of how to gather, organize, and parse real-world data from a variety of sources. The course also provides absolute coverage in developing groundbreaking machine learning pipelines including predictive models, data visualizations, and statistical techniques. Up next, you will learn the thorough utilization of Golang libraries including golearn, gorgonia, gosl, hector, and mat64. You will discover the various TensorFlow capabilities, along with building simple neural networks and integrating them into machine learning models. You will also gain hands-on experience implementing essential machine learning techniques such as regression, classification, and clustering with the relevant Go packages. Furthermore, you will deep dive into the various Go tools that help you build deep neural networks. Lastly, you will become well versed with best practices for machine learning model tuning and optimization. By the end of the course, you will have a solid machine learning mindset and a powerful Go toolkit of techniques, packages, and example implementations."
89,"Machine Learning with R- Machine learning, at its core, is concerned with transforming data into actionable knowledge. R offers a powerful set of machine learning methods to quickly and easily gain insight from your data. Machine Learning with R, This Edition provides a hands-on, readable guide to applying machine learning to real-world problems. Whether you are an experienced R user or new to the language, course teaches you everything you need to uncover key insights, make new predictions, and visualize your findings. This updates the classic R data science course with newer and better libraries, advice on ethical and bias issues in machine learning, and an introduction to deep learning. Find powerful new insights in your data; discover machine learning with R.."
90,"Machine Learning with Scala- Scala is a highly scalable integration of object-oriented nature and functional programming concepts that make it easy to build scalable and complex big data applications. This course is a handy guide for machine learning developers and data scientists who want to develop and train effective machine learning models in Scala. The course starts with an introduction to machine learning, while covering deep learning and machine learning basics. It then explains how to use Scala-based ML libraries to solve classification and regression problems using linear regression, generalized linear regression, logistic regression, support vector machine, and Naïve Bayes algorithms. It also covers tree-based ensemble techniques for solving both classification and regression problems. Moving ahead, it covers unsupervised learning techniques, such as dimensionality reduction, clustering, and recommender systems. Finally, it provides a brief overview of deep learning using a real-life example in Scala."
91,"Q-Learning with Python- Q-learning is a machine learning algorithm used to solve optimization problems in artificial intelligence (AI). It is one of the most popular fields of study among AI researchers. This course starts off by introducing you to reinforcement learning and Q-learning, in addition to helping you become familiar with OpenAI Gym as well as libraries such as Keras and TensorFlow. A few lessons into the course, you will gain insights into model-free Q-learning and use deep Q-networks and double deep Q-networks to solve complex problems. This course will guide you in exploring use cases such as self-driving vehicles and OpenAI Gym’s CartPole problem. You will also learn how to tune and optimize Q-networks and their hyperparameters. As you progress, you will understand the reinforcement learning approach to solving real-world problems. You will also explore how to use Q-learning and related algorithms in scientific research. Toward the end, you’ll gain insight into what’s in store for reinforcement learning. By the end of this course, you will be equipped with the skills you need to solve reinforcement learning problems using Q-learning algorithms with OpenAI Gym, Keras, and TensorFlow"
92,"C# Machine Learning Projects- Machine learning is applied in almost all kinds of real-world surroundings and industries, right from medicine to advertising; from finance to scientifc research. This course will help you learn how to choose a model for your problem, how to evaluate the performance of your models, and how you can use C# to build machine learning models for your future projects. You will get an overview of the machine learning systems and how you, as a C# and .NET developer, can apply your existing knowledge to the wide gamut of intelligent applications, all through a project-based approach. You will start by setting up your C# environment for machine learning with the required packages, Accord.NET, LiveCharts, and Deedle. We will then take you right from building classifcation models for spam email fltering and applying NLP techniques to Twitter sentiment analysis, to time-series and regression analysis for forecasting foreign exchange rates and house prices, as well as drawing insights on customer segments in e-commerce. You will then build a recommendation model for music genre recommendation and an image recognition model for handwritten digits. Lastly, you will learn how to detect anomalies in network and credit card transaction data for cyber attack and credit card fraud detections. By the end of this course, you will be putting your skills in practice and implementing your machine learning knowledge in real projects."
93,"Machine Learning with C#- The necessity for machine learning is everywhere, and most production enterprise applications are written in C# using tools such as Visual Studio, SQL Server, and Microsoft Azur2e. Hands-On Machine Learning with C# uniquely blends together an understanding of various machine learning concepts, techniques of machine learning, and various available machine learning tools through which users can add intelligent features. These tools include image and motion detection, Bayes intuition, and deep learning, to C# .NET applications. Using this course, you will learn to implement supervised and unsupervised learning algorithms and will be better equipped to create excellent predictive models. In addition, you will learn both supervised and unsupervised forms of regression, mainly logistic and linear regression, in depth. Next, you will use the nuML machine learning framework to learn how to create a simple decision tree. In the concluding lessons, you will use the Accord.Net machine learning framework to learn sequence recognition of handwritten numbers using dynamic time warping. We will also cover advanced concepts such as artificial neural networks, autoencoders, and reinforcement learning. By the end of this course, you will have developed a machine learning mindset and will be able to leverage C# tools, techniques, and packages to build smart, predictive, and real-world business applications."
94,"Machine Learning with Microsoft Excel 2019- We have made huge progress in teaching computers to perform difficult tasks, especially those that are repetitive and time-consuming for humans. Excel users, of all levels, can feel left behind by this innovation wave. The truth is that a large amount of the work needed to develop and use a machine learning model can be done in Excel. The course starts by giving a general introduction to machine learning, making every concept clear and understandable. Then, it shows every step of a machine learning project, from data collection, reading from different data sources, developing models, and visualizing the results using Excel features and offerings. In every lesson, there are several examples and hands-on exercises that will show the reader how to combine Excel functions, add-ins, and connections to databases and to cloud services to reach the desired goal: building a full data analysis flow. Different machine learning models are shown, tailored to the type of data to be analyzed."
95,"Machine Learning with JavaScript- In over 20 years of existence, JavaScript has been pushing beyond the boundaries of web evolution with proven existence on servers, embedded devices, Smart TVs, IoT, Smart Cars, and more. Today, with the added advantage of machine learning research and support for JS libraries, JavaScript makes your browsers smarter than ever with the ability to learn patterns and reproduce them to become a part of innovative products and applications. Machine Learning with JavaScript presents various avenues of machine learning in a practical and objective way, and helps implement them using the JavaScript language. Predicting behaviors, analyzing feelings, grouping data, and building neural models are some of the skills you will build from this course. You will learn how to train your machine learning models and work with different kinds of data. During this journey, you will come across use cases such as face detection, spam filtering, recommendation systems, character recognition, and more. Moreover, you will learn how to work with deep neural networks and guide your applications to gain insights from data. By the end of this course, you'll have gained hands-on knowledge on evaluating and implementing the right model, along with choosing from different JS libraries, such as NaturalNode, brain, harthur, classifier, and many more to design smarter applications."
96,"Ensemble Learning with Python- Ensembling is a technique of combining two or more similar or dissimilar machine learning algorithms to create a model that delivers superior predictive power. This course will demonstrate how you can use a variety of weak algorithms to make a strong predictive model. With its hands-on approach, you'll not only get up to speed with the basic theory but also the application of different ensemble learning techniques. Using examples and real-world datasets, you'll be able to produce better machine learning models to solve supervised learning problems such as classification and regression. In addition to this, you'll go on to leverage ensemble learning techniques such as clustering to produce unsupervised machine learning models. As you progress, the lessons will cover different machine learning algorithms that are widely used in the practical world to make predictions and classifications. You'll even get to grips with the use of Python libraries such as scikit-learn and Keras for implementing different ensemble models. By the end of this course, you will be well-versed in ensemble learning, and have the skills you need to understand which ensemble method is required for which problem, and successfully implement them in real-world scenarios."
97,"Machine Learning Fundamentals- As machine learning algorithms become popular, new tools that optimize these algorithms are also developed. Machine Learning Fundamentals explains you how to use the syntax of scikit-learn. You'll study the difference between supervised and unsupervised models, as well as the importance of choosing the appropriate algorithm for each dataset. You'll apply unsupervised clustering algorithms over real-world datasets, to discover patterns and profiles, and explore the process to solve an unsupervised machine learning problem. The focus of the course then shifts to supervised learning algorithms. You'll learn to implement different supervised algorithms and develop neural network structures using the scikit-learn package. You'll also learn how to perform coherent result analysis to improve the performance of the algorithm by tuning hyperparameters. By the end of this course, you will have gain all the skills required to start programming machine learning algorithms."
98,"Machine Learning in Java- As the amount of data in the world continues to grow at an almost incomprehensible rate, being able to understand and process data is becoming a key differentiator for competitive organizations. Machine learning applications are everywhere, from self-driving cars, spam detection, document search, and trading strategies, to speech recognition. This makes machine learning well-suited to the present-day era of big data and Data Science. The main challenge is how to transform data into actionable knowledge. Machine Learning in Java will provide you with the techniques and tools you need. You will start by learning how to apply machine learning methods to a variety of common tasks including classification, prediction, forecasting, market basket analysis, and clustering. The code in this course works for JDK 8 and above, the code is tested on JDK 11. Moving on, you will discover how to detect anomalies and fraud, and ways to perform activity recognition, image recognition, and text analysis. By the end of the course, you will have explored related web resources and technologies that will help you take your learning to the next level. By applying the most effective machine learning methods to real-world problems, you will gain hands-on experience that will transform the way you think about data."
99,"What's New in TensorFlow 2.0- TensorFlow is an end-to-end machine learning platform for experts as well as beginners, and its new version, TensorFlow 2.0 (TF 2.0), improves its simplicity and ease of use. This course will help you understand and utilize the latest TensorFlow features. What's New in TensorFlow 2.0 starts by focusing on advanced concepts such as the new TensorFlow Keras APIs, eager execution, and efficient distribution strategies that help you to run your machine learning models on multiple GPUs and TPUs. The course then takes you through the process of building data ingestion and training pipelines, and it provides recommendations and best practices for feeding data to models created using the new tf.keras API. You will explore the process of building an inference pipeline using TF Serving and other multi-platform deployments before moving on to explore the newly released AIY, which is essentially do-it-yourself AI. This course delves into the core APIs to help you build unified convolutional and recurrent layers and use TensorBoard to visualize deep learning models using what-if analysis. By the end of the course, you'll have learned about compatibility between TF 2.0 and TF 1.x and be able to migrate to TF 2.0 smoothly."
100,"Blockchain Development for Finance Projects- Blockchain technology will continue to play an integral role in the banking and finance sector in the coming years. It will enable enterprises to build transparent and secure business processes. Experts estimate annual savings of up to 20 billion dollars from this technology. This course will help you build financial apps using blockchain, guiding you through enhancing popular products and services in the banking and finance sector. The course starts by explaining the essential concepts of blockchain, and the impact of blockchain technology on the BFSI sector. Next, you'll delve into re-designing existing banking processes and building new financial apps using blockchain. To accomplish this, you'll work through eight blockchain projects. By demonstrating the entire process, the coourse helps you understand everything from setting up the environment and building frontend portals to system integration and testing apps. You will gain hands-on experience with the Ethereum, Hyperledger Fabric, and Stellar to develop private and public decentralized apps. Finally, you'll learn how to use ancillary platforms and frameworks such as IPFS, Truffle OpenZeppelin, and MetaMask."
101,"Machine Learning Bootcamp- In Machine Learning you’ll learn the essentials of machine learning by completing a carefully designed set of real-world projects. Beginning as a novice, you’ll start with the basic concepts of ML before tackling your first challenge: creating a car price predictor using linear regression algorithms. You’ll then advance through increasingly difficult projects, developing your skills to build a churn prediction application, a flight delay calculator, an image classifier, and more. When you’re done working through these fun and informative projects, you’ll have a comprehensive machine learning skill set you can apply to practical on-the-job problems."
102,"Machine Learning with scikit-learn- Scikit-learn is a robust machine learning library for the Python programming language. It provides a set of supervised and unsupervised learning algorithms. This course is the easiest way to learn how to deploy, optimize, and evaluate all of the important machine learning algorithms that scikit-learn provides. This course teaches you how to use scikit-learn for machine learning. You will start by setting up and configuring your machine learning environment with scikit-learn. To put scikit-learn to use, you will learn how to implement various supervised and unsupervised machine learning models. You will learn classification, regression, and clustering techniques to work with different types of datasets and train your models. Finally, you will learn about an effective pipeline to help you build a machine learning project from scratch. By the end of this course, you will be confident in building your own machine learning models for accurate predictions."
103,"Time Series Analysis with R- Time series analysis is the art of extracting meaningful insights from, and revealing patterns in, time series data using statistical and data visualization approaches. These insights and patterns can then be utilized to explore past events and forecast future values in the series. This course explores the basics of time series analysis with R and lays the foundations you need to build forecasting models. You will learn how to preprocess raw time series data and clean and manipulate data with packages such as stats, lubridate, xts, and zoo. You will analyze data and extract meaningful information from it using both descriptive statistics and rich data visualization tools in R such as the TSstudio, plotly, and ggplot2 packages. The later section of the course delves into traditional forecasting models such as time series linear regression, exponential smoothing (Holt, Holt-Winter, and more) and Auto-Regressive Integrated Moving Average (ARIMA) models with the stats and forecast packages. You'll also cover advanced time series regression models with machine learning algorithms such as Random Forest and Gradient Boosting Machine using the h2o package. By the end of this course, you will have the skills needed to explore your data, identify patterns, and build a forecasting model using various traditional and machine learning methods."
104,"Unsupervised Learning with Python- Unsupervised learning is a useful and practical solution in situations where labeled data is not available. Applied Unsupervised Learning with Python guides you on the best practices for using unsupervised learning techniques in tandem with Python libraries and extracting meaningful information from unstructured data. The course begins by explaining how basic clustering works to find similar data points in a set. Once you are well versed with the k-means algorithm and how it operates, you’ll learn what dimensionality reduction is and where to apply it. As you progress, you’ll learn various neural network techniques and how they can improve your model. While studying the applications of unsupervised learning, you will also understand how to mine topics that are trending on Twitter and Facebook and build a news recommendation engine for users. You will complete the course by challenging yourself through various interesting activities such as performing a Market Basket Analysis and identifying relationships between different merchandises. By the end of this course, you will have the skills you need to confidently build your own models using Python."
105,"Applied Unsupervised Learning with Python- Unsupervised learning is about making use of raw, untagged data and applying learning algorithms to it to help a machine predict its outcome. With this course, you will explore the concept of unsupervised learning to cluster large sets of data and analyze them repeatedly until the desired outcome is found using Python. This course starts with the key differences between supervised, unsupervised, and semi-supervised learning. You will be introduced to the best-used libraries and frameworks from the Python ecosystem and address unsupervised learning in both the machine learning and deep learning domains. You will explore various algorithms, techniques that are used to implement unsupervised learning in real-world use cases. You will learn a variety of unsupervised learning approaches, including randomized optimization, clustering, feature selection and transformation, and information theory. You will get hands-on experience with how neural networks can be employed in unsupervised scenarios. You will also explore the steps involved in building and training a GAN in order to process images. By the end of this course, you will have learned the art of unsupervised learning for different real-world challenges."
106,"Machine Learning.- In Machine Learning, expert machine learning engineer Luis Serrano introduces the most valuable ML techniques and teaches you how to make them work for you. You’ll only need high school math to dive into popular approaches and algorithms. Practical examples illustrate each new concept to ensure you’re grokking as you go. You’ll build models for spam detection, language analysis, and image recognition as you lock in each carefully-selected skill. Packed with easy-to-follow Python-based exercises and mini-projects, this course sets you on the path to becoming a machine learning expert. When you’re done, you’ll have an intuitive understanding of the right approach for any machine learning task or project."
107,"Machine Learning Overview.- Machine learning makes it possible to learn about the unknowns and gain hidden insights into your datasets by mastering many tools and techniques. This course guides you to do just that in a very compact manner. After giving a quick overview of what machine learning is all about, Machine Learning Quick Reference jumps right into its core algorithms and demonstrates how they can be applied to real-world scenarios. From model evaluation to optimizing their performance, this course will introduce you to the best practices in machine learning. Furthermore, you will also look at the more advanced aspects such as training neural networks and work with different kinds of data, such as text, time-series, and sequential data. Advanced methods and techniques such as causal inference, deep Gaussian processes, and more are also covered. By the end of this course, you will be able to train fast, accurate machine learning models at your fingertips, which you can easily use as a point of reference"
108,"Applied Supervised Learning with R.- R provides excellent visualization features that are essential for exploring data before using it in automated learning. Applied Supervised Learning with R helps you cover the complete process of employing R to develop applications using supervised machine learning algorithms for your business needs. The course starts by helping you develop your analytical thinking to create a problem statement using business inputs and domain research. You will then learn different evaluation metrics that compare various algorithms, and later progress to using these metrics to select the best algorithm for your problem. After finalizing the algorithm you want to use, you will study the hyperparameter optimization technique to fine-tune your set of optimal parameters. The course demonstrates how you can add different regularization terms to avoid overfitting your model. By the end of this course, you will have gained the advanced skills you need for modeling a supervised machine learning algorithm that precisely fulfills your business needs."
109,"Machine Learning with TensorFlow.js.- TensorFlow.js is a framework that enables you to create performant machine learning (ML) applications that run smoothly in a web browser. With this course, you will learn how to use TensorFlow.js to implement various ML models through an example-based approach. Starting with the basics, you'll understand how ML models can be built on the web. Moving on, you will get to grips with the TensorFlow.js ecosystem to develop applications more efficiently. The course will then guide you through implementing ML techniques and algorithms such as regression, clustering, fast Fourier transform (FFT), and dimensionality reduction. You will later cover the Bellman equation to solve Markov decision process (MDP) problems and understand how it is related to reinforcement learning. Finally, you will explore techniques for deploying ML-based web applications and training models with TensorFlow Core. Throughout this ML course, you'll discover useful tips and tricks that will build on your knowledge. By the end of this course, you will be equipped with the skills you need to create your own web-based ML applications and fine-tune models to achieve high performance."
110,"Python Machine Learning.- Python Machine Learning, This Edition is a comprehensive guide to machine learning and deep learning with Python. It acts as both a step-by-step tutorial, and a reference you'll keep coming back to as you build your machine learning systems. Packed with clear explanations, visualizations, and working examples, the course covers all the essential machine learning techniques in depth. While some course teach you only to follow instructions, with this machine learning course, Raschka and Mirjalili teach the principles behind machine learning, allowing you to build models and applications for yourself. Updated for TensorFlow 2.0, this new edition introduces readers to its new Keras API features, as well as the latest additions to scikit-learn. It's also expanded to cover cutting-edge reinforcement learning techniques based on deep learning, as well as an introduction to GANs. Finally, this course also explores a subfield of natural language processing (NLP) called sentiment analysis, helping you learn how to use machine learning algorithms to classify documents. This course is your companion to machine learning with Python, whether you're a Python developer new to machine learning or want to deepen your knowledge of the latest developments."
111,"Machine Learning Algorithms.- Machine Learning Algorithms helps you harness the real power of machine learning algorithms to implement smarter ways of meeting today's overwhelming data needs. This newly updated and revised guide will help you master algorithms used widely in semi-supervised learning, reinforcement learning, supervised learning, and unsupervised learning domains. You will use all the modern libraries from the Python ecosystem – including NumPy and Kera’s – to extract features from varied complexities of data. Ranging from Bayesian models to the Markov chain Monte Carlo algorithm to Hidden Markov models, this machine learning course teaches you how to extract features from your dataset, perform complex dimensionality reduction, and train supervised and semi-supervised models by making use of Python-based libraries such as scikit-learn. You will also discover practical applications for complex techniques such as maximum likelihood estimation, Hebbian learning, and ensemble learning, and how to use TensorFlow 2.x to train effective deep neural networks. By the end of this course, you will be ready to implement and solve end-to-end machine learning problems and use case scenarios."
112,"One-shot Learning with Python- One-shot learning has been an active field of research for scientists trying to develop a cognitive machine that mimics human learning. With this course, you'll explore key approaches to one-shot learning, such as metrics-based, model-based, and optimization-based techniques, all with the help of practical examples.One-shot Learning with Python will guide you through the exploration and design of deep learning models that can obtain information about an object from one or just a few training samples. The course begins with an overview of deep learning and one-shot learning and then introduces you to the different methods you can use to achieve it, such as deep learning architectures and probabilistic models. Once you've got to grips with the core principles, you'll explore real-world examples and implementations of one-shot learning using PyTorch 1.x on datasets such as Omniglot and MiniImageNet. Finally, you'll explore generative modeling-based methods and discover the key considerations for building systems that exhibit human-level intelligence.By the end of this course, you'll be well-versed with the different one- and few-shot learning methods and be able to use them to build your own deep learning models."
113,"Machine Learning with Go- Machine learning is an essential part of today's data-driven world and is extensively used across industries, including financial forecasting, robotics, and web technology. This course will teach you how to efficiently develop machine learning applications in Go. The course starts with an introduction to machine learning and its development process, explaining the types of problems that it aims to solve and the solutions it offers. It then covers setting up a frictionless Go development environment, including running Go interactively with Jupyter notebooks. Finally, common data processing techniques are introduced. The course then teaches the reader about supervised and unsupervised learning techniques through worked examples that include the implementation of evaluation metrics. These worked examples make use of the prominent open-source libraries GoML and Gonum. The course also teaches readers how to load a pre-trained model and use it to make predictions. It then moves on to the operational side of running machine learning applications: deployment, Continuous Integration, and helpful advice for effective logging and monitoring. At the end of the course, readers will learn how to set up a machine learning project for success, formulating realistic success criteria and accurately translating business requirements into technical ones."
114,"Applied SQL Data Analytics- You already know that you want to learn data analysis with SQL, and a smarter way to learn is to learn by doing. The Applied SQL Data Analytics Workshop focuses on building up your practical skills so that you can navigate and compose custom reports like an expert data analyst. You'll learn from real examples that lead to real results. Throughout The Applied SQL Data Analytics Workshop, you'll take an engaging step-by-step approach to understand data analytics with SQL. You won't have to sit through any unnecessary theory. You can jump into a single exercise each day if you're short on time, or you can spend an entire weekend tinkering with SQLAlchemy and Python. It's your choice. Learning on your terms, you'll build up and reinforce key skills in a way that feels rewarding. Every physical print copy of The Applied SQL Data Analytics Workshop unlocks access to the interactive edition. With videos detailing all exercises and activities, you'll always have a guided solution. You can also benchmark yourself against assessments, track progress, and receive content updates. You'll even earn a secure credential that you can share and verify online upon completion. It's a premium learning experience that's included with your printed copy. To redeem, follow the instructions located at the start of your course. Fast-paced and direct, The Applied SQL Data Analytics Workshop is the ideal companion for SQL beginners. You'll perform SQL queries like a professional data scientist, learning along the way. This process means that you'll find that your new skills stick, embedded as best practice. A solid foundation for the years ahead.."
115,"Supervised Learning- You already know you want to understand supervised learning, and a smarter way to do that is to learn by doing. The Supervised Learning Workshop focuses on building up your practical skills so that you can deploy and build solutions that leverage key supervised learning algorithms. You'll learn from real examples that lead to real results. Throughout The Supervised Learning Workshop, you'll take an engaging step-by-step approach to understand supervised learning. You won't have to sit through any unnecessary theory. If you're short on time you can jump into a single exercise each day or spend an entire weekend learning how to predict future values with auto regressors. It's your choice. Learning on your terms, you'll build up and reinforce key skills in a way that feels rewarding. Every physical print copy of The Supervised Learning Workshop unlocks access to the interactive edition. With videos detailing all exercises and activities, you'll always have a guided solution. You can also benchmark yourself against assessments, track progress, and receive content updates. You'll even earn a secure credential that you can share and verify online upon completion. It's a premium learning experience that's included with your printed copy. To redeem, follow the instructions located at the start of your course. Fast-paced and direct, The Supervised Learning Workshop is the ideal companion for those with some Python background who are getting started with machine learning. You'll learn how to apply key algorithms like a data scientist, learning along the way. This process means that you'll find that your new skills stick, embedded as best practice. A solid foundation for the years ahead."
116,"Supervised Machine Learning with Python- Supervised machine learning is used in a wide range of sectors (such as finance, online advertising, and analytics) because it allows you to train your system to make pricing predictions, campaign adjustments, customer recommendations, and much more while the system self-adjusts and makes decisions on its own. As a result, it's crucial to know how a machine “learns” under the hood. This course will guide you through the implementation and nuances of many popular supervised machine learning algorithms while facilitating a deep understanding along the way. You’ll embark on this journey with a quick overview and see how supervised machine learning differs from unsupervised learning. Next, we explore parametric models such as linear and logistic regression, non-parametric methods such as decision trees, and various clustering techniques to facilitate decision-making and predictions. As we proceed, you'll work hands-on with recommender systems, which are widely used by online companies to increase user interaction and enrich shopping potential. Finally, you’ll wrap up with a brief foray into neural networks and transfer learning. By the end of this course, you’ll be equipped with hands-on techniques and will have gained the practical know-how you need to quickly and powerfully apply algorithms to new problems."
117,"Machine Learning with C++.- C++ can make your machine learning models run faster and more efficiently. This handy guide will help you learn the fundamentals of machine learning (ML), showing you how to use C++ libraries to get the most out of your data. This coursemakes machine learning with C++ for beginners easy with its example-based approach, demonstrating how to implement supervised and unsupervised ML algorithms through real-world examples.This course will get you with tuning and optimizing a model for different use cases, assisting you with model selection and the measurement of performance. You’ll cover techniques such as product recommendations, ensemble learning, and anomaly detection using modern C++ libraries such as PyTorch C++ API, Caffe2, Shogun, Shark-ML, mlpack, and dlib. Next, you’ll explore neural networks and deep learning using examples such as image classification and sentiment analysis, which will help you solve various problems. Later, you’ll learn how to handle production and deployment challenges on mobile and cloud platforms, before discovering how to export and import models using the ONNX format. By the end of this C++ course, you will have real-world machine learning and C++ knowledge, as well as the skills to use C++ to build powerful ML systems."
118,"Natural Language Processing for Hackers- Natural Language Processing for Hackers covers NLP end-to-end, giving you the skills and techniques that allow your computers to speak human. Unlike many research-oriented courses that use the kind of clean datasets you would never find in the real world; this practical guide takes on NLP as you’ll actually use it. You’ll learn the key concepts of NLP by coding your own tools and projects, from a text analysis service right up to a full-featured chatbot. Everything is written in concise, easy-to-read Python code to ensure you’ll grok the most important aspects of Natural Language Processing. When you’re done, you will be able to apply the complete range of NLP techniques to build practical applications—even with messy real-world data."
119,"Machine Learning with ML.NET.- Machine learning (ML) is widely used in many industries such as science, healthcare, and research and its popularity is only growing. In March 2018, Microsoft introduced ML.NET to help .NET enthusiasts in working with ML. With this course, you’ll explore how to build ML.NET applications with the various ML models available using C# code. The course starts by giving you an overview of ML and the types of ML algorithms used, along with covering what ML.NET is and why you need it to build ML apps. You’ll then explore the ML.NET framework, its components, and APIs. The course will serve as a practical guide to helping you build smart apps using the ML.NET library. You’ll gradually become well versed in how to implement ML algorithms such as regression, classification, and clustering with real-world examples and datasets. Each lesson will cover the practical implementation, showing you how to implement ML within .NET applications. You’ll also learn to integrate TensorFlow in ML.NET applications. Later you’ll discover how to store the regression model housing price prediction result to the database and display the real-time predicted results from the database on your web application using ASP.NET Core Blazor and SignalR. By the end of this course, you’ll have learned how to confidently perform basic to advanced-level machine learning tasks in ML.NET."
120,"Machine Learning with TensorFlow- This fully revised edition of Machine Learning with TensorFlow teaches you the foundational concepts of machine learning, and how to utilize the TensorFlow library to rapidly build powerful ML models. You’ll learn the basics of regression, classification, and clustering algorithms, applying them to solve real-world challenges such as call center volume prediction and sentiment analysis of movie reviews. Once you’ve mastered core ML concepts, you’ll move on to the money lessons: exploring cutting-edge neural network techniques such as deep speech classifiers, facial identification, and auto-encoding with CIFAR-10. Digest this course, and you’ll be able to start modelling your everyday problems as automated machine learning tasks."
121,"Zero to AI- Zero to AI teaches business leaders, entrepreneurs, and decision makers how to improve the success and efficiency of their businesses by taking advantage of state-of-the-art AI technologies. After a brief introduction to artificial intelligence, you’ll explore examples that demonstrate how you can use AI for analyzing business data, predicting customer buying trends, deciphering text and images, and much more. The course is filled with extensive, real-world case studies. As you go, you’ll learn how Google applied AI models to improve on century-old engineering rules to save energy (and money) in its data centers. You’ll look under the hood of the models that power Netflix’s video recommendations and see how they compare with the algorithms that Target uses to prepare their customized promotions. For each case study, the authors discuss the best plan of attack, the necessary resources, the possible risk factors, and likely business benefits of the specific AI application. When you’re done, you’ll have a complete roadmap for realizing the vast potential of AI in your own organization!"
122,"Deep Learning with R- Deep Learning with R introduces the world of deep learning using the powerful Keras library and its R language interface. Initially written for Python as Deep Learning with Python by Keras creator and Google AI researcher François Chollet and adapted for R by RStudio founder J. J. Allaire, this course builds your understanding of deep learning through intuitive explanations and practical examples. You'll practice your new skills with R-based applications in computer vision, natural-language processing, and generative models."
123,"Deep Learning with Python- Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. You’ll learn directly from the creator of Keras, François Cholet, building your understanding through intuitive explanations and practical examples. Updated from the original bestseller with over 50% new content, this edition includes new lessons, cutting-edge innovations, and coverage of the very latest deep learning tools. You'll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you finish, you'll have the knowledge and hands-on skills to apply deep learning in your own projects."
124,"Machine Learning.- A machine is said to learn when its performance improves with experience. Learning requires algorithms and programs that capture data and ferret out the interesting or useful patterns. Once the specialized domain of analysts and mathematicians, machine learning is becoming a skill needed by many. Machine Learning is a clearly written tutorial for developers. It avoids academic language and takes you straight to the techniques you'll use in your day-to-day work. Many (Python) examples present the core algorithms of statistical data processing, data analysis, and data visualization in code you can reuse. You'll understand the concepts and how they fit in with tactical tasks like classification, forecasting, recommendations, and higher-level features like summarization and simplification."
125,"Tika- Tika is the ultimate guide to content mining using Apache Tika. You'll learn how to pull usable information from otherwise inaccessible sources, including internet media and file archives. This example-rich course teaches you to build and extend applications based on real-world experience with search engines, digital asset management, and scientific data processing. In addition to architectural overviews, you'll find detailed lessons on features like metadata extraction, automatic language detection, and custom parser development."
126,"Pandas- Pandas makes it easy to dive into Python-based data analysis. You’ll learn to use pandas to automate repetitive spreadsheet functionality and derive insight from data by sorting columns, filtering data subsets, and creating multi-leveled indices. Each lesson is a self-contained tutorial, letting you dip in when you need to troubleshoot tricky problems. Best of all, you won’t be learning from sterile or randomly created data. You’ll start with a variety of datasets that are big, small, incomplete, broken, and messy and learn how to clean and format them for proper analysis"
127,"Learning pandas- You will learn how to use pandas to perform data analysis in Python. You will start with an overview of data analysis and iteratively progress from modeling data, to accessing data from remote sources, performing numeric and statistical analysis, through indexing and performing aggregate analysis, and finally to visualizing statistical data and applying pandas to finance. With the knowledge you gain from this course, you will quickly learn pandas and how it can empower you in the exciting world of data manipulation, analysis and science."
128,"Data Analysis with NumPy and Pandas- Python, a multi-paradigm programming language, has become the language of choice for data scientists for visualization, data analysis, and machine learning. Data Analysis with NumPy and Pandas starts by guiding you in setting up the right environment for data analysis with Python, along with helping you install the correct Python distribution. In addition to this, you will work with the Jupyter notebook and set up a database. Once you have covered Jupyter, you will dig deep into Python’s NumPy package, a powerful extension with advanced mathematical functions. You will then move on to creating NumPy arrays and employing different array methods and functions. You will explore Python’s pandas extension which will help you get to grips with data mining and learn to subset your data. Last but not the least you will grasp how to manage your datasets by sorting and ranking them. By the end of this course, you will have learned to index and group your data for sophisticated data analysis and manipulation."
129,"Turning Spreadsheets into Corporate Data- Spreadsheets are a popular way to store and communicate business data, but, although they are easy to create and update, they are not reliable enough to be used for making important corporate decisions. With this course, you can gain insight into how to maintain spreadsheets, how to format them, and then convert them into a database of reliable and useful information. Turning Spreadsheets into Corporate Data starts with a quick history of spreadsheet usage. You’ll learn the basics of formatting spreadsheets, including how to handle special characters and column headings, and how to convert the spreadsheet first into an intermediate database and then into corporate data. You will also learn how to utilize the mnemonic dictionary that is created along with the intermediate database. The later chapters discuss the immutability of data and the importance of organizational and political considerations during the data transformation. By the end of this course, you’ll have the skills and knowledge needed to convert your spreadsheets into reliable corporate data."
130,"Learning Jupyter 5- The Jupyter Notebook allows you to create and share documents that contain live code, equations, visualizations, and explanatory text. The Jupyter Notebook system is extensively used in domains such as data cleaning and transformation, numerical simulation, statistical modeling, and machine learning. Learning Jupyter 5 will help you get to grips with interactive computing using real-world examples. The bo course ok starts with a detailed overview of the Jupyter Notebook system and its installation in different environments. Next, you will learn to integrate the Jupyter system with different programming languages such as R, Python, Java, JavaScript, and Julia, and explore various versions and packages that are compatible with the Notebook system. Moving ahead, you will master interactive widgets and namespaces and work with Jupyter in a multi-user mode. By the end of this course, you will have used Jupyter with a big dataset and be able to apply all the functionalities you’ve explored throughout the course. You will also have learned all about the Jupyter Notebook and be able to start performing data transformation, numerical simulation, and data visualization."
131,"Data Wrangling with Python- For data to be useful and meaningful, it must be curated and refined. Data Wrangling with Python teaches you the core ideas behind these processes and equips you with knowledge of the most popular tools and techniques in the domain. The course starts with the absolute basics of Python, focusing mainly on data structures. It then delves into the fundamental tools of data wrangling like NumPy and Pandas libraries. You’ll explore useful insights into why you should stay away from traditional ways of data cleaning, as done in other languages, and take advantage of the specialized pre-built routines in Python. This combination of Python tips and tricks will also demonstrate how to use the same Python backend and extract/transform data from an array of sources including the Internet, large database vaults, and Excel financial tables. To help you prepare for more challenging scenarios, you’ll cover how to handle missing or wrong data, and reformat it based on the requirements from the downstream analytics tool. The course will further help you grasp concepts through real-world examples and datasets. By the end of this course, you will be confident in using a diverse array of sources to extract, clean, transform, and format your data efficiently."
132,"Practical Data Wrangling- Around 80% of time in data analysis is spent on cleaning and preparing data for analysis. This is, however, an important task, and is a prerequisite to the rest of the data analysis workflow, including visualization, analysis and reporting. Python and R are considered a popular choice of tool for data analysis, and have packages that can be best used to manipulate different kinds of data, as per your requirements. This course will show you the different data wrangling techniques, and how you can leverage the power of Python and R packages to implement them. You’ll start by understanding the data wrangling process and get a solid foundation to work with different types of data. You’ll work with different data structures and acquire and parse data from various locations. You’ll also see how to reshape the layout of data and manipulate, summarize, and join data sets. Finally, we conclude with a quick primer on accessing and processing data from databases, conducting data exploration, and storing and retrieving data quickly using databases. The course includes practical examples on each of these points using simple and real-world data sets to give you an easier understanding. By the end of the course, you’ll have a thorough understanding of all the data wrangling concepts and how to implement them in the best possible way."
133,"Python Data Structures and Algorithms- Data structures allow you to organize data in a particular way efficiently. They are critical to any problem, provide a complete solution, and act like reusable code. In this course, you will learn the essential Python data structures and the most common algorithms. With this easy-to-read book, you will be able to understand the power of linked lists, double linked lists, and circular linked lists. You will be able to create complex data structures such as graphs, stacks and queues. We will explore the application of binary searches and binary search trees. You will learn the common techniques and structures used in tasks such as preprocessing, modeling, and transforming data. We will also discuss how to organize your code in a manageable, consistent, and extendable way. The course will explore in detail sorting algorithms such as bubble sort, selection sort, insertion sort, and merge sort. By the end of the course, you will learn how to build components that are easy to understand, debug, and use in different applications."
134,"Data Analysis with Python- Data Analysis with Python offers a modern approach to data analysis so that you can work with the latest and most powerful Python tools, AI techniques, and open source libraries. Industry expert David Taieb shows you how to bridge data science with the power of programming and algorithms in Python. You'll be working with complex algorithms, and cutting-edge AI in your data analysis. Learn how to analyze data with hands-on examples using Python-based tools and Jupyter Notebook. You'll find the right balance of theory and practice, with extensive code files that you can integrate right into your own data projects. Explore the power of this approach to data analysis by then working with it across key industry case studies. Four fascinating and full projects connect you to the most critical data analysis challenges you’re likely to meet in today. The first of these is an image recognition application with TensorFlow – embracing the importance today of AI in your data analysis. The second industry project analyses social media trends, exploring big data issues and AI approaches to natural language processing. The third case study is a financial portfolio analysis application that engages you with time series analysis - pivotal to many data science applications today. The fourth industry use case dives you into graph algorithms and the power of programming in modern data science. You'll wrap up with a thoughtful look at the future of data science and how it will harness the power of algorithms and artificial intelligence."
135,"Go Web Scraping- Web scraping is the process of extracting information from the web using various tools that perform scraping and crawling. Go is emerging as the language of choice for scraping using a variety of libraries. This course will quickly explain to you, how to scrape data data from various websites using Go libraries such as Colly and Goquery. The course starts with an introduction to the use cases of building a web scraper and the main features of the Go programming language, along with setting up a Go environment. It then moves on to HTTP requests and responses and talks about how Go handles them. You will also learn about a number of basic web scraping etiquettes. You will be taught how to navigate through a website, using a breadth-first and then a depth-first search, as well as find and follow links. You will get to know about the ways to track history in order to avoid loops and to protect your web scraper using proxies. Finally the course will cover the Go concurrency model, and how to run scrapers in parallel, along with large-scale distributed web scraping."
136,"Feature Engineering Made Easy- Feature engineering is the most important step in creating powerful machine learning systems. This course will take you through the entire feature-engineering journey to make your machine learning much more systematic and effective. You will start with understanding your data—often the success of your ML models depends on how you leverage different feature types, such as continuous, categorical, and more, You will learn when to include a feature, when to omit it, and why, all by understanding error analysis and the acceptability of your models. You will learn to convert a problem statement into useful new features. You will learn to deliver features driven by business needs as well as mathematical insights. You'll also learn how to use machine learning on your machines, automatically learning amazing features for your data. By the end of the course, you will become proficient in Feature Selection, Feature Learning, and Feature Optimization."
137,"Data Analysis with Scala- Efficient business decisions with an accurate sense of business data helps in delivering better performance across products and services. This course helps you to leverage the popular Scala libraries and tools for performing core data analysis tasks with ease. The course begins with a quick overview of the building blocks of a standard data analysis process. You will learn to perform basic tasks like Extraction, Staging, Validation, Cleaning, and Shaping of datasets. You will later deep dive into the data exploration and visualization areas of the data analysis life cycle. You will make use of popular Scala libraries like Saddle, Breeze, Vegas, and Prediction for processing your datasets. You will learn statistical methods for deriving meaningful insights from data. You will also learn to create applications for Apache Spark 2.x on complex data analysis, in real-time. You will discover traditional machine learning techniques for doing data analysis. Furthermore, you will also be introduced to neural networks and deep learning from a data analysis standpoint. By the end of this course, you will be capable of handling large sets of structured and unstructured data, perform exploratory analysis, and building efficient Scala applications for discovering and delivering insights"
138,"Learning Alteryx- Alteryx, as a leading data blending and advanced data analytics platform, has taken self-service data analytics to the next level. Companies worldwide often find themselves struggling to prepare and blend massive datasets that are time-consuming for analysts. Alteryx solves these problems with a repeatable workflow designed to quickly clean, prepare, blend, and join your data in a seamless manner. This course will set you on a self-service data analytics journey that will help you create efficient workflows using Alteryx, without any coding involved. It will empower you and your organization to take well-informed decisions with the help of deeper business insights from the data. Starting with the fundamentals of using Alteryx such as data preparation and blending, you will delve into the more advanced concepts such as performing predictive analytics. You will also learn how to use Alteryx’s features to share the insights gained with the relevant decision makers. To ensure consistency, we will be using data from the Healthcare domain throughout this course. The knowledge you gain from this course will guide you to solve real-life problems related to Business Intelligence confidently. Whether you are a novice with Alteryx or an experienced data analyst keen to explore Alteryx’s self-service analytics features, this course will be the perfect companion for you."
139,"Haskell Data Analysis- Every business and organization that collects data is capable of tapping into its own data to gain insights how to improve. Haskell is a purely functional and lazy programming language, well-suited to handling large data analysis problems. This course will take you through the more difficult problems of data analysis in a hands-on manner. This course will help you get up-to-speed with the basics of data analysis and approaches in the Haskell language. You'll learn about statistical computing, file formats (CSV and SQLite3), descriptive statistics, charts, and progress to more advanced concepts such as understanding the importance of normal distribution. While mathematics is a big part of data analysis, we've tried to keep this course simple and approachable so that you can apply what you learn to the real world. By the end of this course, you will have a thorough understanding of data analysis, and the different ways of analyzing data. You will have a mastery of all the tools and techniques in Haskell for effective data analysis."
140,"Python Feature Engineering Cookbook- Feature engineering is invaluable for developing and enriching your machine learning models. In this cookbook, you will work with the best tools to streamline your feature engineering pipelines and techniques and simplify and improve the quality of your code. Using Python libraries such as pandas, scikit-learn, Feature tools, and Feature-engine, you’ll learn how to work with both continuous and discrete datasets and be able to transform features from unstructured datasets. You will develop the skills necessary to select the best features as well as the most suitable extraction techniques. This course will cover Python recipes that will help you automate feature engineering to simplify complex processes. You’ll also get to grips with different feature engineering strategies, such as the box-cox transform, power transform, and log transform across machine learning, reinforcement learning, and natural language processing (NLP) domains. By the end of this course, you’ll have discovered tips and practical solutions to all of your feature engineering problems."
141,"SciPy Recipes- With the SciPy Stack, you get the power to effectively process, manipulate, and visualize your data using the popular Python language. Utilizing SciPy correctly can sometimes be a very tricky proposition. This course provides the right techniques so you can use SciPy to perform different data science tasks with ease. This course includes hands-on recipes for using the different components of the SciPy Stack such as NumPy, SciPy, matplotlib, and pandas, among others. You will use these libraries to solve real-world problems in linear algebra, numerical analysis, data visualization, and much more. The recipes included in the course will ensure you get a practical understanding not only of how a particular feature in SciPy Stack works, but also of its application to real-world problems. The independent nature of the recipes also ensure that you can pick up any one and learn about a particular feature of SciPy without reading through the other recipes, thus making the course a very handy and useful guide."
142,"Exploratory Data Analysis with Python- Exploratory Data Analysis (EDA) is an approach to data analysis that involves the application of diverse techniques to gain insights into a dataset. This course will help you gain practical knowledge of the main pillars of EDA - data cleaning, data preparation, data exploration, and data visualization. You’ll start by performing EDA using open source datasets and perform simple to advanced analyses to turn data into meaningful insights. You’ll then learn various descriptive statistical techniques to describe the basic characteristics of data and progress to performing EDA on time-series data. As you advance, you’ll learn how to implement EDA techniques for model development and evaluation and build predictive models to visualize results. Using Python for data analysis, you’ll work with real-world datasets, understand data, summarize its characteristics, and visualize it for business intelligence. By the end of this EDA course, you’ll have developed the skills required to carry out a preliminary investigation on any dataset, yield insights into data, present your results with visual aids, and build a model that correctly predicts future outcomes"
143,"SAS for Data Analysis- SAS is one of the leading enterprise tools in the world today when it comes to data management and analysis. It enables the fast and easy processing of data and helps you gain valuable business insights for effective decision-making. This course will serve as a comprehensive guide that will prepare you for the SAS certification exam. After a quick overview of the SAS architecture and components, the course will take you through the different approaches to importing and reading data from different sources using SAS. You will then cover SAS Base and 4GL, understanding data management and analysis, along with exploring SAS functions for data manipulation and transformation. Next, you'll discover SQL procedures and get up to speed on creating and validating queries. In the concluding lessons, you'll learn all about data visualization, right from creating bar charts and sample geographic maps through to assigning patterns and formats. In addition to this, the course will focus on macro programming and its advanced aspects. By the end of this course, you will be well versed in SAS programming and have the skills you need to easily handle and manage your data-related problems in SAS."
144,"R Data Analysis Projects- R offers a large variety of packages and libraries for fast and accurate data analysis and visualization. As a result, it’s one of the most popularly used languages by data scientists and analysts, or anyone who wants to perform data analysis. This course will demonstrate how you can put to use your existing knowledge of data analysis in R to build highly efficient, end-to-end data analysis pipelines without any hassle. You’ll start by building a content-based recommendation system, followed by building a project on sentiment analysis with tweets. You’ll implement time-series modeling for anomaly detection, and understand cluster analysis of streaming data. You’ll work through projects on performing efficient market data research, building recommendation systems, and analyzing networks accurately, all provided with easy to follow codes. With the help of these real-world projects, you’ll get a better understanding of the challenges faced when building data analysis pipelines, and see how you can overcome them without compromising on the efficiency or accuracy of your systems. The course covers some popularly used R packages such as dplyr, ggplot2, RShiny, and others, and includes tips on using them effectively. By the end of this course, you’ll have a better understanding of data analysis with R, and be able to put your knowledge to practical use without any hassle."
145,"Data Analysis with Pandas- Data analysis has become a necessary skill in a variety of domains where knowing how to work with data and extract insights can generate significant value. Data Analysis with Pandas will show you how to analyze your data, get started with machine learning, and work effectively with Python libraries often used for data science, such as pandas, NumPy, matplotlib, seaborn, and scikit-learn. Using real-world datasets, you will learn how to use the powerful pandas library to perform data wrangling to reshape, clean, and aggregate your data. Then, you will be able to conduct exploratory data analysis by calculating summary statistics and visualizing the data to find patterns. In the concluding lessons, you will explore some applications of anomaly detection, regression, clustering, and classification using scikit-learn to make predictions based on past data. By the end of this course, you will be equipped with the skills you need to use pandas to ensure the veracity of your data, visualize it for effective decision-making, and reliably reproduce analyses across multiple datasets."
146,"Exploratory Data Analysis with R- Exploratory Data Analysis with R will help you build not just a foundation but also expertise in the elementary ways to analyze data. You will learn how to understand your data and summarize its main characteristics. You'll also uncover the structure of your data, and you'll learn graphical and numerical techniques using the R language. This course covers the entire exploratory data analysis (EDA) process—data collection, generating statistics, distribution, and invalidating the hypothesis. As you progress through the course, you will learn how to set up a data analysis environment with tools such as ggplot2, knitr, and R Markdown, using tools such as DOE Scatter Plot and SML2010 for multifactor, optimization, and regression data problems. By the end of this course, you will be able to successfully carry out a preliminary investigation on any dataset, identify hidden insights, and present your results in a business context."
147,"Data Analysis with R- Frequently the tool of choice for academics, R has spread deep into the private sector and can be found in the production pipelines at some of the most advanced and successful enterprises. The power and domain-specificity of R allows the user to express complex analytics easily, quickly, and succinctly. Starting with the basics of R and statistical reasoning, this course dives into advanced predictive analytics, showing how to apply those techniques to real-world data though with real-world examples. Packed with engaging problems and exercises, this course begins with a review of R and its syntax with packages like Rcpp, ggplot2, and dplyr. From there, get to grips with the fundamentals of applied statistics and build on this knowledge to perform sophisticated and powerful analytics. Solve the difficulties relating to performing data analysis in practice and find solutions to working with messy data, large data, communicating results, and facilitating reproducibility. This course is engineered to be an invaluable resource through many stages of anyone’s career as a data analyst."
148,"Exploring the Data Jungle- Exploring the Data Jungle: Finding, Preparing, and Using Real-World Data is a collection of three hand-picked lessons introducing you to the often-overlooked art of putting unfamiliar data to good use. Brian Godsey, author of Think Like a Data Scientist, has selected these lessons to help you navigate data in the wild, identify and prepare raw data for analysis, modeling, machine learning, or visualization. As you explore the data jungle, you'll discover real-world examples in Python, R, and other languages suitable for data science."
149,"Visualizing Graph Data- Visualizing Graph Data teaches you how to understand graph data, build graph data structures, and create meaningful visualizations. This engaging course gently introduces graph data visualization through fascinating examples and compelling case studies. You'll discover simple, but effective, techniques to model your data, handle big data, and depict temporal and spatial data. By the end, you'll have a conceptual foundation as well as the practical skills to explore your own data with confidence"
150,"Taming Text- There is so much text in our lives, we are practically drowning in it. Fortunately, there are innovative tools and techniques for managing unstructured information that can throw the smart developer a much-needed lifeline. You'll find them in this course.Taming Text is a practical, example-driven guide to working with text in real applications. This course introduces you to useful techniques like full-text search, proper name recognition, clustering, tagging, information extraction, and summarization. You'll explore real use cases as you systematically absorb the foundations upon which they are built.Written in a clear and concise style, this course avoids jargon, explaining the subject in terms you can understand without a background in statistics or natural language processing. Examples are in Java, but the concepts can be applied in any language."
151,"D3.js- D3.js introduces you to the most powerful web data visualization library available and shows you how to use it to build interactive graphics and data-driven applications. You'll start with dozens of practical use cases that align with different types of charts, networks, and maps using D3's out-of-the-box layouts. Then, you'll explore practical techniques for content design, animation, and representation of dynamic data—including interactive graphics and live streaming data."
152,"Web Scraping with Python- Web scraping is an essential technique used in many organizations to gather valuable data from web pages. This course will enable you to delve into web scraping techniques and methodologies. The course will introduce you to the fundamental concepts of web scraping techniques and how they can be applied to multiple sets of web pages. You'll use powerful libraries from the Python ecosystem such as Scrapy, lxml, pyquery, and bs4 to carry out web scraping operations. You will then get up to speed with simple to intermediate scraping operations such as identifying information from web pages and using patterns or attributes to retrieve information. This course adopts a practical approach to web scraping concepts and tools, guiding you through a series of use cases and showing you how to use the best tools and techniques to efficiently scrape web pages. You'll even cover the use of other popular web scraping tools, such as Selenium, Regex, and web-based APIs. By the end of this course, you will have learned how to efficiently scrape the web using different techniques with Python and other popular tools."
153,"Redis.- Redis introduces Redis and walks you through examples that demonstrate how to use it effectively. You'll begin by getting Redis set up properly and then exploring the key-value model. Then, you'll dive into real use cases including simple caching, distributed ad targeting, and more. You'll learn how to scale Redis from small jobs to massive datasets. Experienced developers will appreciate lessons on clustering and internal scripting to make Redis easier to use."
154,"Machine Learning with Spark 2.x- The purpose of machine learning is to build systems that learn from data. Being able to understand trends and patterns in complex data is critical to success; it is one of the key strategies to unlock growth in the challenging contemporary marketplace today. With the meteoric rise of machine learning, developers are now keen on finding out how can they make their Spark applications smarter.This course gives you access to transform data into actionable knowledge. The course commences by defining machine learning primitives by the MLlib and H2O libraries. You will learn how to use Binary classification to detect the Higgs Boson particle in the huge amount of data produced by CERN particle collider and classify daily health activities using ensemble Methods for Multi-Class Classification. Next, you will solve a typical regression problem involving flight delay predictions and write sophisticated Spark pipelines. You will analyze Twitter data with help of the doc2vec algorithm and K-means clustering. Finally, you will build different pattern mining models using MLlib, perform complex manipulation of DataFrames using Spark and Spark SQL, and deploy your app in a Spark streaming environment."
155,"Solr.- Whether you're handling big (or small) data, managing documents, or building a website, it is important to be able to quickly search through your content and discover meaning in it. Apache Solr is your tool: a ready-to-deploy, Lucene-based, open source, full-text search engine. Solr can scale across many servers to enable real-time queries and data analytics across billions of documents.Solr teaches you to implement scalable search using Apache Solr. This easy-to-read guide balances conceptual discussions with practical examples to show you how to implement all of Solr's core capabilities. You'll master topics like text analysis, faceted search, hit highlighting, result grouping, query suggestions, multilingual search, advanced geospatial and data operations, and relevancy tuning."
156,"Hadoop in Practice- It's always a good time to upgrade your Hadoop skills! Hadoop in Practice, This Edition provides a collection of 104 tested, instantly useful techniques for analyzing real-time streams, moving data securely, machine learning, managing large-scale clusters, and taming big data using Hadoop. This completely revised edition covers changes and new features in Hadoop core, including MapReduce 2 and YARN. You'll pick up hands-on best practices for integrating Spark, Kafka, and Impala with Hadoop, and get new and updated techniques for the latest versions of Flume, Sqoop, and Mahout. In short, this is the most practical, up-to-date coverage of Hadoop available.Readers need to know a programming language like Java and have basic familiarity with Hadoop."
157,"Apache Hadoop 3- Apache Hadoop is a widely used distributed data platform. It enables large datasets to be efficiently processed instead of using one large computer to store and process the data. This course will get you started with the Hadoop ecosystem, and introduce you to the main technical topics, including MapReduce, YARN, and HDFS. The course begins with an overview of big data and Apache Hadoop. Then, you will set up a pseudo Hadoop development environment and a multi-node enterprise Hadoop cluster. You will see how the parallel programming paradigm, such as MapReduce, can solve many complex data processing problems. The course also covers the important aspects of the big data software development lifecycle, including quality assurance and control, performance, administration, and monitoring. You will then learn about the Hadoop ecosystem, and tools such as Kafka, Sqoop, Flume, Pig, Hive, and HBase. Finally, you will look at advanced topics, including real time streaming using Apache Storm, and data analytics using Apache Spark. By the end of the course, you will be well versed with different configurations of the Hadoop 3 cluster."
158,"Apache Hive Essentials- In this course, we prepare you for your journey into big data by frstly introducing you to backgrounds in the big data domain, alongwith the process of setting up and getting familiar with your Hive working environment. Next, the course guides you through discovering and transforming the values of big data with the help of examples. It also hones your skills in using the Hive language in an effcient manner. Toward the end, the course focuses on advanced topics, such as performance, security, and extensions in Hive, which will guide you on exciting adventures on this worthwhile big data journey. By the end of the course, you will be familiar with Hive and able to work effeciently to find solutions to big data problems"
159,"Storm Applied.- Storm Applied is an example-driven guide to processing and analyzing real-time data streams. This immediately useful course starts by teaching you how to design Storm solutions the right way. Then, it quickly dives into real-world case studies that show you how to scale a high-throughput stream processor, ensure smooth operation within a production cluster, and more. Along the way, you'll learn to use Trident for stateful stream processing, along with other tools from the Storm ecosystem.Working in a hands-on learning environment, led by our Apache Storm expert instructor, students will learn about and explore:you learn how to think about designing Storm solutions the right way from day one.But it quickly dives into real-world case studies that will bring the novice up to speed with productionizing Storm."
160,"Big Data- Web-scale applications like social networks, real-time analytics, or e-commerce sites deal with a lot of data, whose volume and velocity exceed the limits of traditional database systems. These applications require architectures built around clusters of machines to store and process data of any size, or speed. Fortunately, scale and simplicity are not mutually exclusive. Big Data teaches you to build big data systems using an architecture designed specifically to capture and analyze web-scale data. This course presents the Lambda Architecture, a scalable, easy-to-understand approach that can be built and run by a small team. You'll explore the theory of big data systems and how to implement them in practice. In addition to discovering a general framework for processing big data, you'll learn specific technologies like Hadoop, Storm, and NoSQL databases."
161,"Apache Spark- Apache Spark is a ﬂexible framework that allows processing of batch and real-time data. Its unified engine has made it quite popular for big data use cases. This course will help you to get started with Apache Spark 2.0 and write big data applications for a variety of use cases. It will also introduce you to Apache Spark – one of the most popular Big Data processing frameworks. Although this course is intended to help you get started with Apache Spark, but it also focuses on explaining the core concepts. This practical guide provides a quick start to the Spark 2.0 architecture and its components. It teaches you how to set up Spark on your local machine. As we move ahead, you will be introduced to resilient distributed datasets (RDDs) and DataFrame APIs, and their corresponding transformations and actions. Then, we move on to the life cycle of a Spark application and learn about the techniques used to debug slow-running applications. You will also go through Spark’s built-in modules for SQL, streaming, machine learning, and graph analysis. Finally, the course will lay out the best practices and optimization techniques that are key for writing efficient Spark applications. By the end of this course, you will have a sound fundamental understanding of the Apache Spark framework and you will be able to write and optimize Spark applications."
162,"Building Data Streaming Applications with Apache Kafka- Apache Kafka is a popular distributed streaming platform that acts as a messaging queue or an enterprise messaging system. It lets you publish and subscribe to a stream of records, and process them in a fault-tolerant way as they occur. This course is a comprehensive guide to designing and architecting enterprise-grade streaming applications using Apache Kafka and other big data tools. It includes best practices for building such applications, and tackles some common challenges such as how to use Kafka efficiently and handle high data volumes with ease. This course first takes you through understanding the type messaging system and then provides a thorough introduction to Apache Kafka and its internal details. The second part of the book takes you through designing streaming application using various frameworks and tools such as Apache Spark, Apache Storm, and more. Once you grasp the basics, we will take you through more advanced concepts in Apache Kafka such as capacity planning and security. By the end of this course, you will have all the information you need to be comfortable with using Apache Kafka, and to design efficient streaming data applications with it."
163,"Spark GraphX.- Spark GraphX begins with the big picture of what graphs can be used for. This example-based tutorial teaches you how to use GraphX interactively. You?ll start with a crystal-clear introduction to building big data graphs from regular data, and then explore the problems and possibilities of implementing graph algorithms and architecting graph processing pipelines. Along the way, you?ll collect practical techniques for enhancing applications and applying machine learning algorithms to graph data."
164,"Streaming Data- Streaming Data is an idea-rich tutorial that teaches you to think about efficiently interacting with fast-flowing data. Through relevant examples and illustrated use cases, you'll explore designs for applications that read, analyze, share, and store streaming data. Along the way, you'll discover the roles of key technologies like Spark, Storm, Kafka, Flink, RabbitMQ, and more. This course offers the perfect balance between big-picture thinking and implementation details"
165,"Elasticsearch- Elasticsearch teaches you how to write applications that deliver professional quality search. As you read, you’ll learn to add basic search features to any application, enhance search results with predictive analysis and relevancy ranking, and use saved data from prior searches to give users a custom experience. This practical course focuses on Elasticsearch’s REST API via HTTP. Code snippets are written mostly in bash using cURL, so they’re easily translatable to other languages"
166,"AI as a Service- AI as a Service teaches you how to quickly harness the power of serverless computing and cloud-based AI services. After an introduction to the basics of this dynamic technology duo, you’ll dive right into your first hands-on serverless AI project: a system that can recognize images from arbitrary web pages. In it you’ll explore tools like Amazon Recognition for image analysis and techniques like deployment of cloud infrastructure, a crawler service, and a simple API. When you’ve mastered the concepts and skills in that fun and interesting project, you’ll move on to building a serverless to-do application that employs cloud-based AI tools like AWS Transcribe and Polly for speech-to-text and text-to-speech functionality and Lex for creating interactive chatbots. When you’re finished with this essential course, you’ll have the skills to quickly build end-to-end serverless AI systems, making you indispensable as this rapidly emerging paradigm becomes the business standard!"
167,"Introduction to DevOps with Kubernetes- Kubernetes and DevOps are the two pillars that can keep your business at the top by ensuring high performance of your IT infrastructure. Introduction to DevOps with Kubernetes will help you develop the skills you need to improve your DevOps with the power of Kubernetes. The course begins with an overview of Kubernetes primitives and DevOps concepts. You'll understand how Kubernetes can assist you with overcoming a wide range of real-world operation challenges. You will get to grips with creating and upgrading a cluster, and then learn how to deploy, update, and scale an application on Kubernetes. As you advance through the lessons, you’ll be able to monitor an application by setting up a pod failure alert on Prometheus. The course will also guide you in configuring Alert manager to send alerts to the Slack channel and trace down a problem on the application using kubectl commands. By the end of this course, you’ll be able to manage the lifecycle of simple to complex applications on Kubernetes with confidence."
168,"Automated Machine Learning- AutoML is designed to automate parts of Machine Learning. Readily available AutoML tools are making data science practitioners’ work easy and are received well in the advanced analytics community. Automated Machine Learning covers the necessary foundation needed to create automated machine learning modules and helps you get up to speed with them in the most practical way possible. In this course, you’ll learn how to automate different tasks in the machine learning pipeline such as data preprocessing, feature selection, model training, model optimization, and much more. In addition to this, it demonstrates how you can use the available automation libraries, such as auto-sklearn and MLBox, and create and extend your own custom AutoML components for Machine Learning. By the end of this course, you will have a clearer understanding of the different aspects of automated Machine Learning, and you’ll be able to incorporate automation tasks using practical datasets. You can leverage your learning from this course to implement Machine Learning in your projects and get a step closer to winning various machine learning competitions."
169,"Real-World Cryptography- Real-World Cryptography helps you understand the cryptographic techniques at work in common tools, frameworks, and protocols so you can make excellent security choices for your systems and applications. There’s no unnecessary theory or jargon—just the most up-to-date techniques you’ll need in your day-to-day work as a developer or systems administrator. Cryptography expert David Wong takes you hands-on with cryptography building blocks such as hash functions and key exchanges, then shows you how to use them as part of your security protocols and applications. Alongside modern methods, the course also anticipates the future of cryptography, diving into emerging and cutting-edge advances such as cryptocurrencies, password-authenticated key exchange, and post-quantum cryptography. Throughout, all techniques are fully illustrated with diagrams and real-world use cases so you can easily see how to put them into practice."
170,"Machine Learning with Azure- Implementing Machine learning (ML) and Artificial Intelligence (AI) in the cloud had not been possible earlier due to the lack of processing power and storage. However, Azure has created ML and AI services that are easy to implement in the cloud. Hands-On Machine Learning with Azure teaches you how to perform advanced ML projects in the cloud in a cost-effective way. The course begins by covering the benefits of ML and AI in the cloud. You will then explore Microsoft’s Team Data Science Process to establish a repeatable process for successful AI development and implementation. You will also gain an understanding of AI technologies available in Azure and the Cognitive Services APIs to integrate them into bot applications. This course lets you explore prebuilt templates with Azure Machine Learning Studio and build a model using canned algorithms that can be deployed as web services. The course then takes you through a preconfigured series of virtual machines in Azure targeted at AI development scenarios. You will get to grips with the ML Server and its capabilities in SQL and HDInsight. In the concluding lessons, you’ll integrate patterns with other non-AI services in Azure."
171,"Cloud Analytics with Microsoft Azure- With data being generated at an exponential speed, organizations all over the world are migrating their infrastructure to the cloud. Application management becomes much easier when you use a cloud platform to build, manage, and deploy your services and applications. Cloud Analytics with Microsoft Azure covers all that you need to extract useful insights from your data. You'll explore the power of data with big data analytics, the Internet of Things (IoT), machine learning, artificial intelligence, and DataOps. You’ll also delve into data analytics by studying use cases that focus on creating actionable insights from near-real-time data. As you advance, you’ll learn to build an end-to-end analytics pipeline on the cloud with machine learning and deep learning concepts. By the end of this course, you'll have developed a solid understanding of data analytics with Azure and its practical implementation."
172,"Machine Learning on Google Cloud Platform- Google Cloud Machine Learning Engine combines the services of Google Cloud Platform with the power and flexibility of TensorFlow. With this course, you will not only learn to build and train different complexities of machine learning models at scale but also host them in the cloud to make predictions. This course is focused on making the most of the Google Machine Learning Platform for large datasets and complex problems. You will learn from scratch how to create powerful machine learning based applications for a wide variety of problems by leveraging different data services from the Google Cloud Platform. Applications include NLP, Speech to text, Reinforcement learning, Time series, recommender systems, image classification, video content inference and many other. We will implement a wide variety of deep learning use cases and also make extensive use of data related services comprising the Google Cloud Platform ecosystem such as Firebase, Storage APIs, Datalab and so forth. This will enable you to integrate Machine Learning and data processing features into your web and mobile applications. By the end of this course, you will know the main difficulties that you may encounter and get appropriate strategies to overcome these difficulties and build efficient systems."
173,"Machine Learning with AWS    - Machine Learning with AWS is the right place to start if you are a beginner interested in learning useful artificial intelligence (AI) and machine learning skills using Amazon Web Services (AWS), the most popular and powerful cloud platform. You will learn how to use AWS to transform your projects into apps that work at high speed and are highly scalable. From natural language processing (NLP) applications, such as language translation and understanding news articles and other text sources, to creating chatbots with both voice and text interfaces, you will learn all that there is to know about using AWS to your advantage. You will also understand how to process huge numbers of images fast and create machine learning models. By the end of this course, you will have developed the skills you need to efficiently use AWS in your machine learning and artificial intelligence projects."
174,"Machine Learning for Cybersecurity - Cyber threats today are one of the costliest losses that an organization can face. In this course, we use the most efficient tool to solve the big problems that exist in the cybersecurity domain. The course begins by giving you the basics of ML in cybersecurity using Python and its libraries. You will explore various ML domains (such as time series analysis and ensemble modeling) to get your foundations right. You will implement various examples such as building system to identify malicious URLs and building a program to detect fraudulent emails and spam. Later, you will learn how to make effective use of K-means algorithm to develop a solution to detect and alert you to any malicious activity in the network. Also learn how to implement biometrics and fingerprint to validate whether the user is a legitimate user or not. Finally, you will see how we change the game with TensorFlow and learn how deep learning is effective for creating models and training systems"
175,"Applied Dark Web Analysis - The overall world wide web is divided into three main areas - the Surface Web, the Deep Web, and the Dark Web. The Deep Web and Dark Web are the two areas which are not accessible through standard search engines or browsers. It becomes extremely important for security professionals to have control over these areas to analyze the security of your organization. This course will initially introduce you to the concept of the Deep Web and the Dark Web and their significance in the security sector. Then we will deep dive into installing operating systems and Tor Browser for privacy, security and anonymity while accessing them. During the course of the course, we will also share some best practices which will be useful in using the tools for best effect. By the end of this course, you will have hands-on experience working with the Deep Web and the Dark Web for security analysis"
